{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting if a person would buy an insurance based on his age and affordability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-28 23:45:50.085468: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "      <th>bought_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  affordibility  bought_insurance\n",
       "0   22              1                 0\n",
       "1   25              0                 0\n",
       "2   47              1                 1\n",
       "3   52              0                 0\n",
       "4   46              1                 1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('insurance_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data using train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[['age', 'affordibility']]\n",
    "y = df['bought_insurance']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing:** Scale the data so that both age and affordibility are in same scaling range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled['age'] = X_train_scaled['age'] / 100\n",
    "\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled['age'] = X_test_scaled['age'] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  affordibility\n",
       "2   0.47              1\n",
       "10  0.18              1\n",
       "21  0.26              0\n",
       "11  0.28              1\n",
       "14  0.49              1\n",
       "9   0.61              1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Building:** First build a model in keras/tensorflow and see what weights and bias values it comes up with. We will than try to reproduce same weights and bias in our plain python implementation of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, input_shape=(2,), activation='sigmoid', kernel_initializer='ones', bias_initializer='zeros')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7113 - accuracy: 0.5000\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7110 - accuracy: 0.5000\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7106 - accuracy: 0.5000\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.7102 - accuracy: 0.5000\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7098 - accuracy: 0.5000\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7094 - accuracy: 0.5000\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7091 - accuracy: 0.5000\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7087 - accuracy: 0.5000\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7083 - accuracy: 0.5000\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7079 - accuracy: 0.5000\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7076 - accuracy: 0.5000\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7072 - accuracy: 0.5000\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7068 - accuracy: 0.5000\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7065 - accuracy: 0.5000\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7061 - accuracy: 0.5000\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7057 - accuracy: 0.5000\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7054 - accuracy: 0.5000\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7050 - accuracy: 0.5000\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7046 - accuracy: 0.5000\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7043 - accuracy: 0.5000\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7039 - accuracy: 0.5000\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7035 - accuracy: 0.5000\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7032 - accuracy: 0.5000\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7028 - accuracy: 0.5000\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7025 - accuracy: 0.5000\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7021 - accuracy: 0.5000\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7017 - accuracy: 0.5000\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7014 - accuracy: 0.5000\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7010 - accuracy: 0.5000\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7007 - accuracy: 0.5000\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7003 - accuracy: 0.5000\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7000 - accuracy: 0.5000\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6996 - accuracy: 0.5000\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6993 - accuracy: 0.5000\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6989 - accuracy: 0.5000\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6986 - accuracy: 0.5000\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6982 - accuracy: 0.5000\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6979 - accuracy: 0.5000\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6975 - accuracy: 0.5000\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6972 - accuracy: 0.5000\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6969 - accuracy: 0.5000\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6965 - accuracy: 0.5000\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6962 - accuracy: 0.5000\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6958 - accuracy: 0.5000\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6955 - accuracy: 0.5000\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6952 - accuracy: 0.5000\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6948 - accuracy: 0.5000\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6945 - accuracy: 0.5000\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6942 - accuracy: 0.5000\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6938 - accuracy: 0.5000\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6935 - accuracy: 0.5000\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6928 - accuracy: 0.5000\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6925 - accuracy: 0.5000\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6922 - accuracy: 0.5000\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6918 - accuracy: 0.5000\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6915 - accuracy: 0.5000\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6912 - accuracy: 0.5000\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6909 - accuracy: 0.5000\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6906 - accuracy: 0.5000\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6902 - accuracy: 0.5000\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6899 - accuracy: 0.5000\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6896 - accuracy: 0.5000\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6893 - accuracy: 0.5000\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6890 - accuracy: 0.5000\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6886 - accuracy: 0.5000\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6883 - accuracy: 0.5000\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6880 - accuracy: 0.5000\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6877 - accuracy: 0.5000\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6874 - accuracy: 0.5000\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6871 - accuracy: 0.5000\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6868 - accuracy: 0.5000\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6865 - accuracy: 0.5000\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6862 - accuracy: 0.5000\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6859 - accuracy: 0.5000\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6856 - accuracy: 0.5000\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6853 - accuracy: 0.5000\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6849 - accuracy: 0.5000\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6846 - accuracy: 0.5000\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6843 - accuracy: 0.5000\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6840 - accuracy: 0.5000\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6838 - accuracy: 0.5000\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6835 - accuracy: 0.5000\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6832 - accuracy: 0.5000\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6829 - accuracy: 0.5000\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6826 - accuracy: 0.5000\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6823 - accuracy: 0.5000\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6820 - accuracy: 0.5000\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6817 - accuracy: 0.5000\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6814 - accuracy: 0.5000\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6811 - accuracy: 0.5000\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6808 - accuracy: 0.5000\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6805 - accuracy: 0.5000\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6803 - accuracy: 0.5000\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6800 - accuracy: 0.5000\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6797 - accuracy: 0.5000\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6794 - accuracy: 0.5000\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6791 - accuracy: 0.5000\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6788 - accuracy: 0.5000\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6786 - accuracy: 0.5000\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6783 - accuracy: 0.5000\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6780 - accuracy: 0.5000\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6777 - accuracy: 0.5000\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6775 - accuracy: 0.5000\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6772 - accuracy: 0.5000\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6769 - accuracy: 0.5000\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6766 - accuracy: 0.5000\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6764 - accuracy: 0.5000\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6761 - accuracy: 0.5000\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6758 - accuracy: 0.5000\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6756 - accuracy: 0.5000\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6753 - accuracy: 0.5000\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6750 - accuracy: 0.5000\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6748 - accuracy: 0.5000\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6745 - accuracy: 0.5000\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6742 - accuracy: 0.5000\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6740 - accuracy: 0.5000\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6737 - accuracy: 0.5000\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6735 - accuracy: 0.5000\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6732 - accuracy: 0.5000\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6730 - accuracy: 0.5000\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6727 - accuracy: 0.5000\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6724 - accuracy: 0.5000\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6722 - accuracy: 0.5000\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6719 - accuracy: 0.5000\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6717 - accuracy: 0.5000\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6714 - accuracy: 0.5000\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6712 - accuracy: 0.5000\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6709 - accuracy: 0.5000\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6707 - accuracy: 0.5000\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6704 - accuracy: 0.5000\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6702 - accuracy: 0.5000\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6699 - accuracy: 0.5000\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6697 - accuracy: 0.5000\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6695 - accuracy: 0.5000\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6692 - accuracy: 0.5000\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6690 - accuracy: 0.5000\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6687 - accuracy: 0.5000\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6685 - accuracy: 0.5000\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6683 - accuracy: 0.5000\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6680 - accuracy: 0.5000\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6678 - accuracy: 0.5000\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6675 - accuracy: 0.5000\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6673 - accuracy: 0.5000\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6671 - accuracy: 0.5000\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6668 - accuracy: 0.5000\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6666 - accuracy: 0.5000\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6664 - accuracy: 0.5000\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6661 - accuracy: 0.5000\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6659 - accuracy: 0.5000\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6657 - accuracy: 0.5000\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6655 - accuracy: 0.5000\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6652 - accuracy: 0.5000\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6650 - accuracy: 0.5000\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6648 - accuracy: 0.5000\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6646 - accuracy: 0.5000\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6643 - accuracy: 0.5000\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6641 - accuracy: 0.5000\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6639 - accuracy: 0.5000\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6637 - accuracy: 0.5000\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6635 - accuracy: 0.5000\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6632 - accuracy: 0.5000\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6630 - accuracy: 0.5000\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6628 - accuracy: 0.5000\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6626 - accuracy: 0.5000\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6624 - accuracy: 0.5000\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6622 - accuracy: 0.5000\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6620 - accuracy: 0.5000\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6617 - accuracy: 0.5000\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6615 - accuracy: 0.5000\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6613 - accuracy: 0.5000\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6611 - accuracy: 0.5000\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6609 - accuracy: 0.5455\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6607 - accuracy: 0.5455\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6605 - accuracy: 0.5455\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6603 - accuracy: 0.5455\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6601 - accuracy: 0.5455\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6599 - accuracy: 0.5455\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6597 - accuracy: 0.5455\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6595 - accuracy: 0.5455\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6593 - accuracy: 0.5455\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6591 - accuracy: 0.5455\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6589 - accuracy: 0.5455\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6587 - accuracy: 0.5455\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6585 - accuracy: 0.5455\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6583 - accuracy: 0.5455\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6581 - accuracy: 0.5455\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6579 - accuracy: 0.5455\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6577 - accuracy: 0.5455\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6575 - accuracy: 0.5455\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6573 - accuracy: 0.5455\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6571 - accuracy: 0.5455\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6569 - accuracy: 0.5455\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6568 - accuracy: 0.5455\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6566 - accuracy: 0.5455\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.6564 - accuracy: 0.5455\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6562 - accuracy: 0.5455\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6560 - accuracy: 0.5455\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6558 - accuracy: 0.5455\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6556 - accuracy: 0.5455\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6555 - accuracy: 0.5455\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6553 - accuracy: 0.5455\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6551 - accuracy: 0.5455\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6549 - accuracy: 0.5455\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6547 - accuracy: 0.5455\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6545 - accuracy: 0.5455\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6544 - accuracy: 0.5455\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6542 - accuracy: 0.5455\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6540 - accuracy: 0.5455\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6538 - accuracy: 0.5455\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6537 - accuracy: 0.5455\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6535 - accuracy: 0.5455\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6533 - accuracy: 0.5455\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6531 - accuracy: 0.5455\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6530 - accuracy: 0.5455\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6528 - accuracy: 0.5455\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6526 - accuracy: 0.5455\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6525 - accuracy: 0.5455\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.6523 - accuracy: 0.5455\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6521 - accuracy: 0.5455\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6519 - accuracy: 0.5455\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6518 - accuracy: 0.5455\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6516 - accuracy: 0.5455\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6515 - accuracy: 0.5455\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6513 - accuracy: 0.5455\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6511 - accuracy: 0.5455\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6510 - accuracy: 0.5455\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6508 - accuracy: 0.5455\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.6506 - accuracy: 0.5455\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6505 - accuracy: 0.5455\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6503 - accuracy: 0.5455\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6502 - accuracy: 0.5455\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6500 - accuracy: 0.5455\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6498 - accuracy: 0.5455\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6497 - accuracy: 0.5455\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6495 - accuracy: 0.5455\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6494 - accuracy: 0.5455\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6492 - accuracy: 0.5455\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6491 - accuracy: 0.5455\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6489 - accuracy: 0.5455\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6488 - accuracy: 0.5455\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6486 - accuracy: 0.5909\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6485 - accuracy: 0.5909\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6483 - accuracy: 0.5909\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6482 - accuracy: 0.5909\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6480 - accuracy: 0.5909\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6479 - accuracy: 0.5909\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6477 - accuracy: 0.5909\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6476 - accuracy: 0.5909\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6474 - accuracy: 0.5909\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6473 - accuracy: 0.5909\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6471 - accuracy: 0.5909\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6470 - accuracy: 0.5909\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6468 - accuracy: 0.5909\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6467 - accuracy: 0.5909\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6465 - accuracy: 0.5909\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6464 - accuracy: 0.5909\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6463 - accuracy: 0.5909\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6461 - accuracy: 0.6364\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6460 - accuracy: 0.6364\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6458 - accuracy: 0.6364\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6457 - accuracy: 0.6364\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6456 - accuracy: 0.6364\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.6454 - accuracy: 0.6364\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6453 - accuracy: 0.6364\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6452 - accuracy: 0.6364\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6450 - accuracy: 0.6364\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6449 - accuracy: 0.6364\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6448 - accuracy: 0.6364\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.6446 - accuracy: 0.6364\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6445 - accuracy: 0.6364\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6444 - accuracy: 0.6364\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6442 - accuracy: 0.6364\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6441 - accuracy: 0.6364\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6440 - accuracy: 0.6364\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6438 - accuracy: 0.6364\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.6437 - accuracy: 0.6364\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6436 - accuracy: 0.6364\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6435 - accuracy: 0.6364\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6433 - accuracy: 0.6364\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6432 - accuracy: 0.6364\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6431 - accuracy: 0.6364\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6430 - accuracy: 0.6364\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6428 - accuracy: 0.6364\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6427 - accuracy: 0.6364\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6426 - accuracy: 0.6364\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6425 - accuracy: 0.6364\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6423 - accuracy: 0.6364\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6422 - accuracy: 0.6364\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6421 - accuracy: 0.6364\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6420 - accuracy: 0.6364\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6419 - accuracy: 0.6364\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6417 - accuracy: 0.6364\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6416 - accuracy: 0.6364\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6415 - accuracy: 0.6364\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6414 - accuracy: 0.6364\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6413 - accuracy: 0.6364\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6411 - accuracy: 0.6364\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.6410 - accuracy: 0.6364\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6409 - accuracy: 0.6364\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6408 - accuracy: 0.6364\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.6407 - accuracy: 0.6364\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6406 - accuracy: 0.6364\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6405 - accuracy: 0.6364\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6403 - accuracy: 0.6364\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6402 - accuracy: 0.6364\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6401 - accuracy: 0.6364\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6400 - accuracy: 0.6364\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6399 - accuracy: 0.6364\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6398 - accuracy: 0.6364\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6397 - accuracy: 0.6364\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6396 - accuracy: 0.6364\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6395 - accuracy: 0.6364\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6394 - accuracy: 0.6364\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6392 - accuracy: 0.6364\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6391 - accuracy: 0.6364\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6390 - accuracy: 0.6364\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6389 - accuracy: 0.6364\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6388 - accuracy: 0.6364\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6387 - accuracy: 0.6364\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6386 - accuracy: 0.6364\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6385 - accuracy: 0.6364\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6384 - accuracy: 0.6364\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6383 - accuracy: 0.6364\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6382 - accuracy: 0.6364\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6381 - accuracy: 0.6364\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6380 - accuracy: 0.6364\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6379 - accuracy: 0.6364\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6378 - accuracy: 0.6364\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6377 - accuracy: 0.6364\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6376 - accuracy: 0.6364\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6375 - accuracy: 0.6364\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6374 - accuracy: 0.6364\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6373 - accuracy: 0.6364\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6372 - accuracy: 0.6364\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6371 - accuracy: 0.6364\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6370 - accuracy: 0.6364\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6369 - accuracy: 0.6364\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6368 - accuracy: 0.6364\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6367 - accuracy: 0.6364\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6366 - accuracy: 0.6364\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6365 - accuracy: 0.6364\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6364 - accuracy: 0.6364\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6363 - accuracy: 0.6364\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6362 - accuracy: 0.6364\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6361 - accuracy: 0.6364\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6361 - accuracy: 0.6364\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6360 - accuracy: 0.6364\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6359 - accuracy: 0.6364\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6358 - accuracy: 0.6364\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6357 - accuracy: 0.6364\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6356 - accuracy: 0.6364\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6355 - accuracy: 0.6364\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6354 - accuracy: 0.6364\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6353 - accuracy: 0.6364\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6352 - accuracy: 0.6364\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6352 - accuracy: 0.6364\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6351 - accuracy: 0.6364\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6350 - accuracy: 0.6364\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6349 - accuracy: 0.6364\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6348 - accuracy: 0.6364\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.6347 - accuracy: 0.6364\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6346 - accuracy: 0.6364\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6345 - accuracy: 0.6364\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6345 - accuracy: 0.6364\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6344 - accuracy: 0.6364\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6343 - accuracy: 0.6364\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6342 - accuracy: 0.6364\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6341 - accuracy: 0.6364\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6340 - accuracy: 0.6364\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6339 - accuracy: 0.6364\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6339 - accuracy: 0.6364\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6338 - accuracy: 0.6364\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6337 - accuracy: 0.6364\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6336 - accuracy: 0.6364\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6335 - accuracy: 0.6364\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.6335 - accuracy: 0.6364\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6334 - accuracy: 0.6364\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6333 - accuracy: 0.6364\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6332 - accuracy: 0.6364\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6331 - accuracy: 0.6364\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6331 - accuracy: 0.6364\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6330 - accuracy: 0.6364\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6329 - accuracy: 0.6364\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6328 - accuracy: 0.6364\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6327 - accuracy: 0.6364\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6327 - accuracy: 0.6364\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6326 - accuracy: 0.6364\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6325 - accuracy: 0.6364\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6324 - accuracy: 0.6364\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.6323 - accuracy: 0.6364\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6323 - accuracy: 0.6364\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6322 - accuracy: 0.6364\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6321 - accuracy: 0.6364\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6320 - accuracy: 0.6364\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6320 - accuracy: 0.6364\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6319 - accuracy: 0.6364\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6318 - accuracy: 0.6364\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6317 - accuracy: 0.6364\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.6317 - accuracy: 0.6364\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6316 - accuracy: 0.6364\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6315 - accuracy: 0.6364\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6314 - accuracy: 0.6364\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6314 - accuracy: 0.6364\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6313 - accuracy: 0.6364\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6312 - accuracy: 0.6364\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6312 - accuracy: 0.6364\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6311 - accuracy: 0.6364\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6310 - accuracy: 0.6364\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6309 - accuracy: 0.6364\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6309 - accuracy: 0.6364\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6308 - accuracy: 0.6364\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6307 - accuracy: 0.6364\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6307 - accuracy: 0.6364\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6306 - accuracy: 0.6364\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6305 - accuracy: 0.6364\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6305 - accuracy: 0.6364\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6304 - accuracy: 0.6364\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6303 - accuracy: 0.6364\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6302 - accuracy: 0.6364\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6302 - accuracy: 0.6364\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6301 - accuracy: 0.6364\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6300 - accuracy: 0.6364\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6300 - accuracy: 0.6364\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6299 - accuracy: 0.6364\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6298 - accuracy: 0.6364\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6298 - accuracy: 0.6364\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6297 - accuracy: 0.6364\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6296 - accuracy: 0.6364\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6296 - accuracy: 0.6364\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6295 - accuracy: 0.6364\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6294 - accuracy: 0.6364\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6294 - accuracy: 0.6364\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6293 - accuracy: 0.6364\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6292 - accuracy: 0.6364\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6292 - accuracy: 0.6364\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6291 - accuracy: 0.6364\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6290 - accuracy: 0.6364\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6290 - accuracy: 0.6364\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6289 - accuracy: 0.6364\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6288 - accuracy: 0.6364\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6288 - accuracy: 0.6364\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6287 - accuracy: 0.6364\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6287 - accuracy: 0.6364\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6286 - accuracy: 0.6364\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6285 - accuracy: 0.6364\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6285 - accuracy: 0.6364\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6284 - accuracy: 0.6364\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6283 - accuracy: 0.6364\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6283 - accuracy: 0.6364\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6282 - accuracy: 0.6364\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6282 - accuracy: 0.6364\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6281 - accuracy: 0.6364\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6280 - accuracy: 0.6364\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6280 - accuracy: 0.6364\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6279 - accuracy: 0.6364\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6278 - accuracy: 0.6364\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6278 - accuracy: 0.6364\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6277 - accuracy: 0.6364\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6277 - accuracy: 0.6364\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6276 - accuracy: 0.6364\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6275 - accuracy: 0.6364\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.6275 - accuracy: 0.6364\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6274 - accuracy: 0.6364\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.6274 - accuracy: 0.6364\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6273 - accuracy: 0.6364\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6272 - accuracy: 0.6364\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6272 - accuracy: 0.6364\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6271 - accuracy: 0.6364\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6271 - accuracy: 0.6364\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6270 - accuracy: 0.6364\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6269 - accuracy: 0.6364\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6269 - accuracy: 0.6364\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6268 - accuracy: 0.6364\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6268 - accuracy: 0.6364\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6267 - accuracy: 0.6364\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6267 - accuracy: 0.6364\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6266 - accuracy: 0.6364\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6265 - accuracy: 0.6364\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6265 - accuracy: 0.6364\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6264 - accuracy: 0.6364\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6264 - accuracy: 0.6364\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6263 - accuracy: 0.6364\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6262 - accuracy: 0.6364\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6262 - accuracy: 0.6364\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6261 - accuracy: 0.6364\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6261 - accuracy: 0.6364\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6260 - accuracy: 0.6364\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6260 - accuracy: 0.6364\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6259 - accuracy: 0.6364\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6259 - accuracy: 0.6364\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6258 - accuracy: 0.6364\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6257 - accuracy: 0.6364\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6257 - accuracy: 0.6364\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6256 - accuracy: 0.6364\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6256 - accuracy: 0.6364\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6255 - accuracy: 0.6364\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6255 - accuracy: 0.6364\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6254 - accuracy: 0.6364\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6253 - accuracy: 0.6364\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6253 - accuracy: 0.6364\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6252 - accuracy: 0.6364\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6252 - accuracy: 0.6364\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6251 - accuracy: 0.6364\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6251 - accuracy: 0.6364\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6250 - accuracy: 0.6364\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6250 - accuracy: 0.6364\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6249 - accuracy: 0.6364\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6249 - accuracy: 0.6364\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6248 - accuracy: 0.6364\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6247 - accuracy: 0.6364\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6247 - accuracy: 0.6364\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6246 - accuracy: 0.6364\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6246 - accuracy: 0.6364\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6245 - accuracy: 0.6364\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6245 - accuracy: 0.6364\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6244 - accuracy: 0.6364\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6244 - accuracy: 0.6364\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6243 - accuracy: 0.6818\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6243 - accuracy: 0.6818\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6242 - accuracy: 0.6818\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6242 - accuracy: 0.6818\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6241 - accuracy: 0.6818\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6241 - accuracy: 0.6818\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6240 - accuracy: 0.6818\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6239 - accuracy: 0.6818\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6239 - accuracy: 0.6818\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6238 - accuracy: 0.6818\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6238 - accuracy: 0.6818\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6237 - accuracy: 0.6818\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6237 - accuracy: 0.6818\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6236 - accuracy: 0.6818\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6236 - accuracy: 0.6818\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6235 - accuracy: 0.6818\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6235 - accuracy: 0.6818\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6234 - accuracy: 0.6818\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6234 - accuracy: 0.6818\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6233 - accuracy: 0.6818\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6233 - accuracy: 0.6818\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6232 - accuracy: 0.6818\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6232 - accuracy: 0.6818\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6231 - accuracy: 0.6818\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6231 - accuracy: 0.6818\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6230 - accuracy: 0.6818\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6230 - accuracy: 0.6818\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6229 - accuracy: 0.6818\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6229 - accuracy: 0.6818\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6228 - accuracy: 0.6818\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6227 - accuracy: 0.6818\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6227 - accuracy: 0.6818\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6226 - accuracy: 0.6818\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6226 - accuracy: 0.6818\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6225 - accuracy: 0.6818\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6225 - accuracy: 0.6818\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6224 - accuracy: 0.6818\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6224 - accuracy: 0.6818\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6223 - accuracy: 0.6818\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6223 - accuracy: 0.6818\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6222 - accuracy: 0.6818\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6222 - accuracy: 0.6818\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6221 - accuracy: 0.6818\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6221 - accuracy: 0.6818\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6220 - accuracy: 0.6818\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6220 - accuracy: 0.6818\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6219 - accuracy: 0.6818\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6219 - accuracy: 0.6818\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6218 - accuracy: 0.6818\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6218 - accuracy: 0.6818\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6217 - accuracy: 0.6818\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6217 - accuracy: 0.6818\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6216 - accuracy: 0.6818\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6216 - accuracy: 0.6818\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6215 - accuracy: 0.6818\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6215 - accuracy: 0.6818\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6214 - accuracy: 0.6818\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6214 - accuracy: 0.6818\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6213 - accuracy: 0.6818\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6213 - accuracy: 0.6818\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6212 - accuracy: 0.6818\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6212 - accuracy: 0.6818\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6211 - accuracy: 0.6818\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6211 - accuracy: 0.6818\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6210 - accuracy: 0.6818\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6210 - accuracy: 0.6818\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6209 - accuracy: 0.6818\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6209 - accuracy: 0.7273\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6208 - accuracy: 0.7273\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6208 - accuracy: 0.7273\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6207 - accuracy: 0.7273\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6207 - accuracy: 0.7273\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6206 - accuracy: 0.7273\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6206 - accuracy: 0.7273\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6205 - accuracy: 0.7273\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6205 - accuracy: 0.7273\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6204 - accuracy: 0.7273\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6204 - accuracy: 0.7273\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6203 - accuracy: 0.7273\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6203 - accuracy: 0.7273\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6202 - accuracy: 0.7273\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.6202 - accuracy: 0.7273\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6201 - accuracy: 0.7273\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6201 - accuracy: 0.7273\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6200 - accuracy: 0.7273\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6200 - accuracy: 0.7273\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6200 - accuracy: 0.7273\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6199 - accuracy: 0.7273\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6199 - accuracy: 0.7273\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6198 - accuracy: 0.7273\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6198 - accuracy: 0.7273\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6197 - accuracy: 0.7273\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6197 - accuracy: 0.7273\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6196 - accuracy: 0.7273\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6196 - accuracy: 0.7273\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6195 - accuracy: 0.7273\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6195 - accuracy: 0.7273\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6194 - accuracy: 0.7273\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6194 - accuracy: 0.7273\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6193 - accuracy: 0.7273\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6193 - accuracy: 0.7273\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6192 - accuracy: 0.7273\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6192 - accuracy: 0.7273\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6191 - accuracy: 0.7273\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6191 - accuracy: 0.7273\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6190 - accuracy: 0.7273\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6190 - accuracy: 0.7273\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6189 - accuracy: 0.7273\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6189 - accuracy: 0.7273\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6188 - accuracy: 0.7273\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6188 - accuracy: 0.7273\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6187 - accuracy: 0.7273\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6187 - accuracy: 0.7273\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6186 - accuracy: 0.7273\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6186 - accuracy: 0.7273\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6185 - accuracy: 0.7273\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6185 - accuracy: 0.7273\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6184 - accuracy: 0.7273\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6184 - accuracy: 0.7273\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6183 - accuracy: 0.7273\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6183 - accuracy: 0.7273\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6182 - accuracy: 0.7273\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6182 - accuracy: 0.7273\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6181 - accuracy: 0.7273\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6181 - accuracy: 0.7273\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6181 - accuracy: 0.7273\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6180 - accuracy: 0.7273\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6180 - accuracy: 0.7273\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6179 - accuracy: 0.7273\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6179 - accuracy: 0.7273\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6178 - accuracy: 0.7273\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6178 - accuracy: 0.7273\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6177 - accuracy: 0.7273\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6177 - accuracy: 0.7273\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6176 - accuracy: 0.7273\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6176 - accuracy: 0.7273\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6175 - accuracy: 0.7273\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6175 - accuracy: 0.7273\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6174 - accuracy: 0.7273\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6174 - accuracy: 0.7273\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6173 - accuracy: 0.7273\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6173 - accuracy: 0.7273\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6172 - accuracy: 0.7273\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6172 - accuracy: 0.7273\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6171 - accuracy: 0.7273\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6171 - accuracy: 0.7273\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6170 - accuracy: 0.7273\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6170 - accuracy: 0.7273\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6169 - accuracy: 0.7273\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6169 - accuracy: 0.7273\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6168 - accuracy: 0.7273\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6168 - accuracy: 0.7273\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6167 - accuracy: 0.7273\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6167 - accuracy: 0.7273\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6166 - accuracy: 0.7273\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6166 - accuracy: 0.7273\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6166 - accuracy: 0.7273\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6165 - accuracy: 0.7273\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.6165 - accuracy: 0.7273\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6164 - accuracy: 0.7273\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6164 - accuracy: 0.7273\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6163 - accuracy: 0.7273\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6163 - accuracy: 0.7273\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6162 - accuracy: 0.7273\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6162 - accuracy: 0.7273\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6161 - accuracy: 0.7273\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6161 - accuracy: 0.7273\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6160 - accuracy: 0.7273\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6160 - accuracy: 0.7273\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6159 - accuracy: 0.7273\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6159 - accuracy: 0.7273\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6158 - accuracy: 0.7273\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6158 - accuracy: 0.7273\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6157 - accuracy: 0.7273\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6157 - accuracy: 0.7273\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6156 - accuracy: 0.7273\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6156 - accuracy: 0.7273\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6155 - accuracy: 0.7273\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6155 - accuracy: 0.7273\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6154 - accuracy: 0.7273\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6154 - accuracy: 0.7273\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6153 - accuracy: 0.7273\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6153 - accuracy: 0.7273\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6153 - accuracy: 0.7273\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6152 - accuracy: 0.7273\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6152 - accuracy: 0.7273\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6151 - accuracy: 0.7273\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6151 - accuracy: 0.7273\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6150 - accuracy: 0.7273\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6150 - accuracy: 0.7273\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6149 - accuracy: 0.7273\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6149 - accuracy: 0.7273\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6148 - accuracy: 0.7273\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6148 - accuracy: 0.7273\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6147 - accuracy: 0.7273\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6147 - accuracy: 0.7273\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6146 - accuracy: 0.7273\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6146 - accuracy: 0.7273\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6145 - accuracy: 0.7273\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6145 - accuracy: 0.7273\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6144 - accuracy: 0.7273\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6144 - accuracy: 0.7273\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6143 - accuracy: 0.7273\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6143 - accuracy: 0.7273\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6142 - accuracy: 0.7273\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.6142 - accuracy: 0.7273\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6141 - accuracy: 0.7273\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6141 - accuracy: 0.7273\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6140 - accuracy: 0.7273\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6140 - accuracy: 0.7273\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6139 - accuracy: 0.7273\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6139 - accuracy: 0.7273\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6138 - accuracy: 0.7273\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6138 - accuracy: 0.7273\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6138 - accuracy: 0.7273\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6137 - accuracy: 0.7273\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6137 - accuracy: 0.7273\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6136 - accuracy: 0.7273\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6136 - accuracy: 0.7273\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6135 - accuracy: 0.7273\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6135 - accuracy: 0.7273\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6134 - accuracy: 0.7273\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6134 - accuracy: 0.7273\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6133 - accuracy: 0.7273\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6133 - accuracy: 0.7273\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6132 - accuracy: 0.7273\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6132 - accuracy: 0.7273\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6131 - accuracy: 0.7273\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6131 - accuracy: 0.7273\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6130 - accuracy: 0.7273\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6130 - accuracy: 0.7273\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6129 - accuracy: 0.7273\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6129 - accuracy: 0.7273\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6128 - accuracy: 0.7273\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6128 - accuracy: 0.7273\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6127 - accuracy: 0.7273\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6127 - accuracy: 0.7273\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6126 - accuracy: 0.7273\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6126 - accuracy: 0.7273\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6125 - accuracy: 0.7273\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6125 - accuracy: 0.7273\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6124 - accuracy: 0.7273\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6124 - accuracy: 0.7273\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6123 - accuracy: 0.7273\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6123 - accuracy: 0.7273\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6122 - accuracy: 0.7273\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6122 - accuracy: 0.7273\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6122 - accuracy: 0.7273\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6121 - accuracy: 0.7273\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6121 - accuracy: 0.7273\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6120 - accuracy: 0.7273\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6120 - accuracy: 0.7273\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6119 - accuracy: 0.7273\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6119 - accuracy: 0.7273\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6118 - accuracy: 0.7273\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6118 - accuracy: 0.7273\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6117 - accuracy: 0.7273\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6117 - accuracy: 0.7273\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6116 - accuracy: 0.7273\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6116 - accuracy: 0.7273\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6115 - accuracy: 0.7273\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6115 - accuracy: 0.7273\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6114 - accuracy: 0.7273\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6114 - accuracy: 0.7273\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6113 - accuracy: 0.7273\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6113 - accuracy: 0.7273\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6112 - accuracy: 0.7273\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6112 - accuracy: 0.7273\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6111 - accuracy: 0.7273\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6111 - accuracy: 0.7273\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6110 - accuracy: 0.7273\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6110 - accuracy: 0.7273\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6109 - accuracy: 0.7273\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6109 - accuracy: 0.7273\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6108 - accuracy: 0.7273\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6108 - accuracy: 0.7273\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6107 - accuracy: 0.7273\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6107 - accuracy: 0.7273\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6106 - accuracy: 0.7273\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6106 - accuracy: 0.7273\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6105 - accuracy: 0.7273\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6105 - accuracy: 0.7273\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6104 - accuracy: 0.7273\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6104 - accuracy: 0.7273\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6104 - accuracy: 0.7273\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6103 - accuracy: 0.7273\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6103 - accuracy: 0.7273\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6102 - accuracy: 0.7273\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6102 - accuracy: 0.7273\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6101 - accuracy: 0.7273\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6101 - accuracy: 0.7273\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6100 - accuracy: 0.7273\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6100 - accuracy: 0.7273\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6099 - accuracy: 0.7273\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6099 - accuracy: 0.7273\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6098 - accuracy: 0.7273\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6098 - accuracy: 0.7273\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6097 - accuracy: 0.7273\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6097 - accuracy: 0.7273\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6096 - accuracy: 0.7273\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6096 - accuracy: 0.7273\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6095 - accuracy: 0.7273\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6095 - accuracy: 0.7273\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6094 - accuracy: 0.7273\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6094 - accuracy: 0.7273\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6093 - accuracy: 0.7273\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6093 - accuracy: 0.7273\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6092 - accuracy: 0.7273\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6092 - accuracy: 0.7273\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6091 - accuracy: 0.7273\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6091 - accuracy: 0.7273\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6090 - accuracy: 0.7273\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6090 - accuracy: 0.7273\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6089 - accuracy: 0.7273\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6089 - accuracy: 0.7273\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6088 - accuracy: 0.7273\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6088 - accuracy: 0.7273\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6087 - accuracy: 0.7273\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6087 - accuracy: 0.7273\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6086 - accuracy: 0.7273\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6086 - accuracy: 0.7273\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6085 - accuracy: 0.7273\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6085 - accuracy: 0.7273\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6084 - accuracy: 0.7273\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6084 - accuracy: 0.7273\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6083 - accuracy: 0.7273\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6083 - accuracy: 0.7273\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6082 - accuracy: 0.7273\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6082 - accuracy: 0.7273\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6081 - accuracy: 0.7273\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6081 - accuracy: 0.7273\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6080 - accuracy: 0.7273\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6080 - accuracy: 0.7273\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6080 - accuracy: 0.7273\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6079 - accuracy: 0.7273\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6079 - accuracy: 0.7273\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6078 - accuracy: 0.7273\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6078 - accuracy: 0.7273\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6077 - accuracy: 0.7273\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6077 - accuracy: 0.7273\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6076 - accuracy: 0.7273\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6076 - accuracy: 0.7273\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6075 - accuracy: 0.7273\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.6075 - accuracy: 0.7273\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6074 - accuracy: 0.7273\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6074 - accuracy: 0.7273\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6073 - accuracy: 0.7273\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6073 - accuracy: 0.7273\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6072 - accuracy: 0.7273\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6072 - accuracy: 0.7273\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6071 - accuracy: 0.7273\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6071 - accuracy: 0.7273\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6070 - accuracy: 0.7273\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6070 - accuracy: 0.7273\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6069 - accuracy: 0.7273\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6069 - accuracy: 0.7273\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6068 - accuracy: 0.7273\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6068 - accuracy: 0.7273\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6067 - accuracy: 0.7273\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6067 - accuracy: 0.7273\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6066 - accuracy: 0.7273\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6066 - accuracy: 0.7273\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6065 - accuracy: 0.7273\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6065 - accuracy: 0.7273\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6064 - accuracy: 0.7273\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6064 - accuracy: 0.7273\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6063 - accuracy: 0.7273\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6063 - accuracy: 0.7273\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6062 - accuracy: 0.7273\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6062 - accuracy: 0.7273\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6061 - accuracy: 0.7273\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6061 - accuracy: 0.7273\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6060 - accuracy: 0.7273\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6060 - accuracy: 0.7273\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6059 - accuracy: 0.7273\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6059 - accuracy: 0.7273\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6058 - accuracy: 0.7273\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6058 - accuracy: 0.7273\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6057 - accuracy: 0.7273\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6057 - accuracy: 0.7273\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6056 - accuracy: 0.6818\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6056 - accuracy: 0.6818\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6055 - accuracy: 0.6818\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6055 - accuracy: 0.6818\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6054 - accuracy: 0.6818\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6054 - accuracy: 0.6818\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6053 - accuracy: 0.6818\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6053 - accuracy: 0.6818\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6052 - accuracy: 0.6818\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6052 - accuracy: 0.6818\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6051 - accuracy: 0.6818\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6051 - accuracy: 0.6818\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6050 - accuracy: 0.6818\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6050 - accuracy: 0.6818\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6049 - accuracy: 0.6818\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6049 - accuracy: 0.6818\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6048 - accuracy: 0.6818\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6048 - accuracy: 0.6818\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6047 - accuracy: 0.6818\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6047 - accuracy: 0.6818\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6046 - accuracy: 0.6818\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6046 - accuracy: 0.6818\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6045 - accuracy: 0.6818\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6045 - accuracy: 0.6818\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6044 - accuracy: 0.6818\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6044 - accuracy: 0.6818\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6043 - accuracy: 0.6818\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6043 - accuracy: 0.6818\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6042 - accuracy: 0.6818\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6042 - accuracy: 0.6818\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6041 - accuracy: 0.6818\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6041 - accuracy: 0.6818\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6040 - accuracy: 0.6818\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6040 - accuracy: 0.6818\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6040 - accuracy: 0.6818\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6039 - accuracy: 0.6818\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6039 - accuracy: 0.6818\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6038 - accuracy: 0.6818\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6038 - accuracy: 0.6818\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6037 - accuracy: 0.6818\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6037 - accuracy: 0.6818\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6036 - accuracy: 0.6818\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6036 - accuracy: 0.6818\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6035 - accuracy: 0.6818\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6035 - accuracy: 0.6818\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6034 - accuracy: 0.6818\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6034 - accuracy: 0.6818\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6033 - accuracy: 0.6818\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6033 - accuracy: 0.6818\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6032 - accuracy: 0.6818\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6032 - accuracy: 0.6818\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6031 - accuracy: 0.6818\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6031 - accuracy: 0.6818\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6030 - accuracy: 0.6818\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6030 - accuracy: 0.6818\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6029 - accuracy: 0.6818\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6029 - accuracy: 0.6818\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6028 - accuracy: 0.6818\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6028 - accuracy: 0.6818\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6027 - accuracy: 0.6818\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6027 - accuracy: 0.6818\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6026 - accuracy: 0.6818\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6026 - accuracy: 0.6818\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6025 - accuracy: 0.6818\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6025 - accuracy: 0.6818\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6024 - accuracy: 0.6818\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6024 - accuracy: 0.6818\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6023 - accuracy: 0.6818\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6023 - accuracy: 0.6818\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6022 - accuracy: 0.6818\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6022 - accuracy: 0.6818\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6021 - accuracy: 0.6818\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6021 - accuracy: 0.6818\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6020 - accuracy: 0.6818\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6020 - accuracy: 0.6818\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6019 - accuracy: 0.6818\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6019 - accuracy: 0.6818\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6018 - accuracy: 0.6818\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6018 - accuracy: 0.6818\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6017 - accuracy: 0.6818\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6017 - accuracy: 0.6818\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6016 - accuracy: 0.6818\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6016 - accuracy: 0.6818\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6015 - accuracy: 0.6818\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6015 - accuracy: 0.6818\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6014 - accuracy: 0.6818\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6014 - accuracy: 0.6818\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6013 - accuracy: 0.6818\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6013 - accuracy: 0.6818\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6012 - accuracy: 0.6818\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6012 - accuracy: 0.6818\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6011 - accuracy: 0.6818\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6011 - accuracy: 0.6818\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6010 - accuracy: 0.6818\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6010 - accuracy: 0.6818\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6009 - accuracy: 0.6818\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6009 - accuracy: 0.6818\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6008 - accuracy: 0.6818\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6008 - accuracy: 0.6818\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6007 - accuracy: 0.6818\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6007 - accuracy: 0.6818\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6006 - accuracy: 0.6818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fc99c06d840>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 334ms/step - loss: 0.5855 - accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5854937434196472, 0.6666666865348816]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 199ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6447142 ],\n",
       "       [0.56694895],\n",
       "       [0.40433905],\n",
       "       [0.5943529 ],\n",
       "       [0.6498545 ],\n",
       "       [0.6799389 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     1\n",
       "10    0\n",
       "21    0\n",
       "11    0\n",
       "14    1\n",
       "9     1\n",
       "Name: bought_insurance, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.1257615],\n",
       "        [0.7468925]], dtype=float32),\n",
       " array([-0.680116], dtype=float32))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef, intercept = model.get_weights()\n",
    "coef, intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means w1 = 1.1257615, w2 = 0.7468925, bias = -0.680116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(X):\n",
    "    return 1 / (1 + math.exp(-X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999847700205"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of model.predict, we can write our own prediction function that uses w1, w2 and bias as parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_function(age, affordibility):\n",
    "    w1 = coef[0]\n",
    "    w2 = coef[1]\n",
    "    b = intercept\n",
    "\n",
    "    weighted_sum = w1 * age + w2 * affordibility + b\n",
    "    return sigmoid(weighted_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6g/zbv6zp2s0yjfhrt83s_n6gj40000gn/T/ipykernel_95841/850877310.py:4: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return 1 / (1 + math.exp(-X))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5669489366110878"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_function(.18, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start implementing gradient descent in plain python. Again the goal is to come up with same w1, w2 and bias that keras model calculated. We want to show how keras/tensorflow would have computed these values internally using gradient descent\n",
    "\n",
    "First write couple of helper routines such as sigmoid and log_loss (binary_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999998, 0.5       , 0.73105858])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid_np(X):\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "\n",
    "sigmoid_np(np.array([18, 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(y_true, y_predicted):\n",
    "    epsilon = 1e-15\n",
    "    y_predicted_new = [max(i,epsilon) for i in y_predicted]\n",
    "    y_predicted_new = [min(i,1-epsilon) for i in y_predicted_new]\n",
    "    y_predicted_new = np.array(y_predicted_new)\n",
    "    return -np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right now comes the time to implement our final gradient descent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(age, affordability, y_true, epochs, loss_threshold):\n",
    "    w1 = w2 = 1\n",
    "    b = 0\n",
    "    lr = 0.01\n",
    "    n = len(age)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        weighted_sum = w1 * age + w2 * affordability + b\n",
    "        y_pred = sigmoid_np(weighted_sum)\n",
    "        loss = log_loss(y_true, y_pred)\n",
    "\n",
    "        w1_d = (1/n) * np.dot(np.transpose(age), (y_pred - y_true))\n",
    "        w2_d = (1/n) * np.dot(np.transpose(affordability), (y_pred - y_true))\n",
    "        b_d = np.mean(y_pred - y_true)\n",
    "\n",
    "        w1 = w1 - lr * w1_d\n",
    "        w2 = w2 - lr * w2_d\n",
    "        b = b - lr * b_d\n",
    "\n",
    "        print(f'Epoch:{i}, w1:{w1}, w2:{w2}, bias:{b}, loss:{loss}')\n",
    "\n",
    "        if loss < loss_threshold:\n",
    "            break\n",
    "\n",
    "    return w1, w2, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, w1:0.9994981526694036, w2:0.9989669625078906, bias:-0.0022683735472737165, loss:0.7113403233723417\n",
      "Epoch:1, w1:0.9989985401110477, w2:0.9979374183112477, bias:-0.004531110245838688, loss:0.7106947453938027\n",
      "Epoch:2, w1:0.9985011596734701, w2:0.9969113648213787, bias:-0.006788217377105742, loss:0.7100526623879727\n",
      "Epoch:3, w1:0.9980060086810597, w2:0.9958887993990542, bias:-0.009039702278981612, loss:0.7094140604774263\n",
      "Epoch:4, w1:0.9975130844342297, w2:0.9948697193547812, bias:-0.011285572345427677, loss:0.7087789257803064\n",
      "Epoch:5, w1:0.9970223842095907, w2:0.993854121949078, bias:-0.013525835026017508, loss:0.708147244410992\n",
      "Epoch:6, w1:0.9965339052601244, w2:0.9928420043927506, bias:-0.015760497825493266, loss:0.7075190024807606\n",
      "Epoch:7, w1:0.9960476448153585, w2:0.9918333638471725, bias:-0.01798956830332102, loss:0.7068941860984489\n",
      "Epoch:8, w1:0.9955636000815411, w2:0.9908281974245644, bias:-0.020213054073245, loss:0.7062727813711064\n",
      "Epoch:9, w1:0.995081768241817, w2:0.9898265021882776, bias:-0.022430962802840876, loss:0.7056547744046482\n",
      "Epoch:10, w1:0.9946021464564033, w2:0.9888282751530783, bias:-0.024643302213068055, loss:0.7050401513045004\n",
      "Epoch:11, w1:0.9941247318627662, w2:0.9878335132854335, bias:-0.026850080077821113, loss:0.7044288981762432\n",
      "Epoch:12, w1:0.9936495215757978, w2:0.9868422135037993, bias:-0.029051304223480342, loss:0.7038210011262495\n",
      "Epoch:13, w1:0.9931765126879942, w2:0.9858543726789107, bias:-0.03124698252846151, loss:0.7032164462623174\n",
      "Epoch:14, w1:0.9927057022696331, w2:0.9848699876340727, bias:-0.03343712292276484, loss:0.7026152196943014\n",
      "Epoch:15, w1:0.9922370873689522, w2:0.9838890551454533, bias:-0.03562173338752331, loss:0.7020173075347361\n",
      "Epoch:16, w1:0.9917706650123286, w2:0.9829115719423782, bias:-0.03780082195455023, loss:0.7014226958994565\n",
      "Epoch:17, w1:0.991306432204457, w2:0.9819375347076267, bias:-0.03997439670588627, loss:0.7008313709082156\n",
      "Epoch:18, w1:0.9908443859285306, w2:0.9809669400777294, bias:-0.042142465773345836, loss:0.700243318685294\n",
      "Epoch:19, w1:0.9903845231464199, w2:0.9799997846432674, bias:-0.04430503733806299, loss:0.6996585253601076\n",
      "Epoch:20, w1:0.9899268407988536, w2:0.9790360649491724, bias:-0.04646211963003683, loss:0.6990769770678098\n",
      "Epoch:21, w1:0.9894713358055992, w2:0.9780757774950286, bias:-0.04861372092767645, loss:0.6984986599498891\n",
      "Epoch:22, w1:0.9890180050656435, w2:0.9771189187353762, bias:-0.050759849557345506, loss:0.6979235601547609\n",
      "Epoch:23, w1:0.9885668454573742, w2:0.9761654850800154, bias:-0.05290051389290646, loss:0.6973516638383569\n",
      "Epoch:24, w1:0.9881178538387609, w2:0.9752154728943127, bias:-0.05503572235526446, loss:0.6967829571647078\n",
      "Epoch:25, w1:0.9876710270475374, w2:0.9742688784995068, bias:-0.057165483411911, loss:0.6962174263065225\n",
      "Epoch:26, w1:0.9872263619013827, w2:0.9733256981730181, bias:-0.05928980557646737, loss:0.6956550574457601\n",
      "Epoch:27, w1:0.9867838551981037, w2:0.9723859281487565, bias:-0.06140869740822787, loss:0.6950958367742014\n",
      "Epoch:28, w1:0.9863435037158175, w2:0.9714495646174328, bias:-0.063522167511703, loss:0.69453975049401\n",
      "Epoch:29, w1:0.985905304213133, w2:0.9705166037268695, bias:-0.06563022453616243, loss:0.6939867848182939\n",
      "Epoch:30, w1:0.9854692534293349, w2:0.9695870415823133, bias:-0.06773287717517802, loss:0.6934369259716588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:31, w1:0.9850353480845648, w2:0.9686608742467487, bias:-0.06983013416616679, loss:0.6928901601907568\n",
      "Epoch:32, w1:0.9846035848800053, w2:0.9677380977412119, bias:-0.07192200428993396, loss:0.692346473724831\n",
      "Epoch:33, w1:0.984173960498062, w2:0.9668187080451064, bias:-0.07400849637021605, loss:0.6918058528362555\n",
      "Epoch:34, w1:0.983746471602547, w2:0.9659027010965188, bias:-0.07608961927322401, loss:0.6912682838010689\n",
      "Epoch:35, w1:0.9833211148388618, w2:0.9649900727925357, bias:-0.07816538190718672, loss:0.6907337529095036\n",
      "Epoch:36, w1:0.9828978868341801, w2:0.9640808189895617, bias:-0.08023579322189446, loss:0.690202246466511\n",
      "Epoch:37, w1:0.9824767841976315, w2:0.9631749355036373, bias:-0.08230086220824277, loss:0.689673750792279\n",
      "Epoch:38, w1:0.9820578035204839, w2:0.9622724181107587, bias:-0.08436059789777652, loss:0.6891482522227479\n",
      "Epoch:39, w1:0.981640941376327, w2:0.9613732625471968, bias:-0.08641500936223429, loss:0.6886257371101183\n",
      "Epoch:40, w1:0.9812261943212554, w2:0.9604774645098182, bias:-0.08846410571309318, loss:0.6881061918233548\n",
      "Epoch:41, w1:0.9808135588940513, w2:0.9595850196564062, bias:-0.09050789610111391, loss:0.6875896027486861\n",
      "Epoch:42, w1:0.980403031616368, w2:0.9586959236059822, bias:-0.09254638971588643, loss:0.6870759562900971\n",
      "Epoch:43, w1:0.979994608992912, w2:0.957810171939128, bias:-0.09457959578537596, loss:0.6865652388698186\n",
      "Epoch:44, w1:0.9795882875116267, w2:0.9569277601983084, bias:-0.09660752357546955, loss:0.68605743692881\n",
      "Epoch:45, w1:0.9791840636438743, w2:0.9560486838881941, bias:-0.09863018238952317, loss:0.6855525369272379\n",
      "Epoch:46, w1:0.978781933844619, w2:0.9551729384759855, bias:-0.10064758156790943, loss:0.6850505253449485\n",
      "Epoch:47, w1:0.9783818945526088, w2:0.9543005193917363, bias:-0.10265973048756578, loss:0.6845513886819368\n",
      "Epoch:48, w1:0.9779839421905585, w2:0.953431422028678, bias:-0.10466663856154357, loss:0.6840551134588074\n",
      "Epoch:49, w1:0.9775880731653311, w2:0.9525656417435443, bias:-0.10666831523855756, loss:0.6835616862172337\n",
      "Epoch:50, w1:0.9771942838681202, w2:0.9517031738568957, bias:-0.10866477000253635, loss:0.6830710935204094\n",
      "Epoch:51, w1:0.9768025706746315, w2:0.9508440136534453, bias:-0.11065601237217347, loss:0.6825833219534952\n",
      "Epoch:52, w1:0.9764129299452644, w2:0.9499881563823832, bias:-0.11264205190047921, loss:0.6820983581240623\n",
      "Epoch:53, w1:0.9760253580252932, w2:0.9491355972577028, bias:-0.1146228981743334, loss:0.6816161886625267\n",
      "Epoch:54, w1:0.9756398512450484, w2:0.9482863314585257, bias:-0.11659856081403892, loss:0.6811368002225829\n",
      "Epoch:55, w1:0.9752564059200969, w2:0.947440354129428, bias:-0.1185690494728762, loss:0.6806601794816293\n",
      "Epoch:56, w1:0.9748750183514231, w2:0.9465976603807656, bias:-0.12053437383665856, loss:0.6801863131411888\n",
      "Epoch:57, w1:0.974495684825609, w2:0.945758245289001, bias:-0.12249454362328852, loss:0.6797151879273255\n",
      "Epoch:58, w1:0.9741184016150138, w2:0.9449221038970279, bias:-0.12444956858231511, loss:0.6792467905910556\n",
      "Epoch:59, w1:0.9737431649779541, w2:0.9440892312144982, bias:-0.12639945849449222, loss:0.6787811079087517\n",
      "Epoch:60, w1:0.9733699711588824, w2:0.9432596222181472, bias:-0.12834422317133792, loss:0.6783181266825439\n",
      "Epoch:61, w1:0.9729988163885667, w2:0.9424332718521197, bias:-0.13028387245469492, loss:0.6778578337407153\n",
      "Epoch:62, w1:0.9726296968842689, w2:0.9416101750282954, bias:-0.13221841621629207, loss:0.6774002159380907\n",
      "Epoch:63, w1:0.9722626088499231, w2:0.9407903266266145, bias:-0.1341478643573071, loss:0.6769452601564231\n",
      "Epoch:64, w1:0.971897548476313, w2:0.9399737214954034, bias:-0.13607222680793035, loss:0.6764929533047712\n",
      "Epoch:65, w1:0.9715345119412502, w2:0.9391603544516991, bias:-0.1379915135269299, loss:0.676043282319876\n",
      "Epoch:66, w1:0.9711734954097504, w2:0.938350220281575, bias:-0.1399057345012177, loss:0.6755962341665279\n",
      "Epoch:67, w1:0.9708144950342107, w2:0.9375433137404651, bias:-0.14181489974541722, loss:0.675151795837933\n",
      "Epoch:68, w1:0.9704575069545854, w2:0.9367396295534883, bias:-0.143719019301432, loss:0.6747099543560701\n",
      "Epoch:69, w1:0.9701025272985621, w2:0.9359391624157731, bias:-0.14561810323801583, loss:0.6742706967720457\n",
      "Epoch:70, w1:0.9697495521817366, w2:0.9351419069927805, bias:-0.14751216165034417, loss:0.6738340101664425\n",
      "Epoch:71, w1:0.9693985777077884, w2:0.9343478579206281, bias:-0.14940120465958684, loss:0.6733998816496635\n",
      "Epoch:72, w1:0.9690495999686543, w2:0.9335570098064128, bias:-0.15128524241248206, loss:0.672968298362269\n",
      "Epoch:73, w1:0.9687026150447029, w2:0.9327693572285332, bias:-0.15316428508091207, loss:0.6725392474753118\n",
      "Epoch:74, w1:0.968357619004908, w2:0.9319848947370122, bias:-0.15503834286148005, loss:0.6721127161906647\n",
      "Epoch:75, w1:0.9680146079070213, w2:0.9312036168538184, bias:-0.15690742597508853, loss:0.6716886917413443\n",
      "Epoch:76, w1:0.9676735777977447, w2:0.9304255180731872, bias:-0.15877154466651916, loss:0.6712671613918284\n",
      "Epoch:77, w1:0.9673345247129023, w2:0.9296505928619415, bias:-0.16063070920401423, loss:0.6708481124383708\n",
      "Epoch:78, w1:0.9669974446776117, w2:0.9288788356598118, bias:-0.16248492987885946, loss:0.6704315322093081\n",
      "Epoch:79, w1:0.966662333706455, w2:0.9281102408797556, bias:-0.16433421700496842, loss:0.6700174080653636\n",
      "Epoch:80, w1:0.9663291878036486, w2:0.9273448029082766, bias:-0.1661785809184686, loss:0.6696057273999457\n",
      "Epoch:81, w1:0.9659980029632131, w2:0.9265825161057427, bias:-0.16801803197728898, loss:0.6691964776394415\n",
      "Epoch:82, w1:0.9656687751691423, w2:0.9258233748067038, bias:-0.1698525805607492, loss:0.6687896462435043\n",
      "Epoch:83, w1:0.9653415003955717, w2:0.9250673733202088, bias:-0.1716822370691504, loss:0.6683852207053382\n",
      "Epoch:84, w1:0.9650161746069462, w2:0.9243145059301215, bias:-0.17350701192336768, loss:0.6679831885519761\n",
      "Epoch:85, w1:0.964692793758188, w2:0.9235647668954369, bias:-0.1753269155644443, loss:0.6675835373445534\n",
      "Epoch:86, w1:0.9643713537948623, w2:0.922818150450595, bias:-0.17714195845318748, loss:0.6671862546785771\n",
      "Epoch:87, w1:0.964051850653344, w2:0.9220746508057961, bias:-0.17895215106976592, loss:0.6667913281841898\n",
      "Epoch:88, w1:0.9637342802609831, w2:0.9213342621473131, bias:-0.18075750391330916, loss:0.6663987455264286\n",
      "Epoch:89, w1:0.9634186385362691, w2:0.9205969786378041, bias:-0.18255802750150857, loss:0.6660084944054808\n",
      "Epoch:90, w1:0.9631049213889953, w2:0.9198627944166247, bias:-0.18435373237022004, loss:0.6656205625569313\n",
      "Epoch:91, w1:0.9627931247204224, w2:0.919131703600138, bias:-0.18614462907306872, loss:0.6652349377520096\n",
      "Epoch:92, w1:0.9624832444234412, w2:0.918403700282025, bias:-0.18793072818105527, loss:0.6648516077978288\n",
      "Epoch:93, w1:0.9621752763827345, w2:0.9176787785335936, bias:-0.1897120402821641, loss:0.6644705605376213\n",
      "Epoch:94, w1:0.9618692164749385, w2:0.9169569324040865, bias:-0.19148857598097335, loss:0.6640917838509703\n",
      "Epoch:95, w1:0.9615650605688042, w2:0.9162381559209886, bias:-0.19326034589826682, loss:0.663715265654035\n",
      "Epoch:96, w1:0.9612628045253567, w2:0.9155224430903331, bias:-0.19502736067064766, loss:0.6633409938997725\n",
      "Epoch:97, w1:0.9609624441980549, w2:0.9148097878970074, bias:-0.19678963095015398, loss:0.6629689565781548\n",
      "Epoch:98, w1:0.96066397543295, w2:0.9141001843050565, bias:-0.19854716740387637, loss:0.662599141716381\n",
      "Epoch:99, w1:0.9603673940688435, w2:0.9133936262579867, bias:-0.20029998071357738, loss:0.6622315373790851\n",
      "Epoch:100, w1:0.9600726959374444, w2:0.9126901076790683, bias:-0.20204808157531276, loss:0.6618661316685395\n",
      "Epoch:101, w1:0.9597798768635254, w2:0.9119896224716364, bias:-0.2037914806990548, loss:0.661502912724853\n",
      "Epoch:102, w1:0.9594889326650792, w2:0.911292164519391, bias:-0.20553018880831755, loss:0.6611418687261663\n",
      "Epoch:103, w1:0.9591998591534727, w2:0.9105977276866964, bias:-0.20726421663978403, loss:0.6607829878888407\n",
      "Epoch:104, w1:0.9589126521336021, w2:0.9099063058188794, bias:-0.20899357494293538, loss:0.6604262584676442\n",
      "Epoch:105, w1:0.9586273074040456, w2:0.9092178927425257, bias:-0.21071827447968206, loss:0.660071668755932\n",
      "Epoch:106, w1:0.9583438207572164, w2:0.9085324822657763, bias:-0.21243832602399693, loss:0.6597192070858239\n",
      "Epoch:107, w1:0.9580621879795148, w2:0.9078500681786218, bias:-0.21415374036155052, loss:0.6593688618283757\n",
      "Epoch:108, w1:0.9577824048514794, w2:0.9071706442531959, bias:-0.21586452828934816, loss:0.6590206213937482\n",
      "Epoch:109, w1:0.9575044671479369, w2:0.9064942042440682, bias:-0.21757070061536923, loss:0.6586744742313704\n",
      "Epoch:110, w1:0.9572283706381526, w2:0.905820741888535, bias:-0.2192722681582085, loss:0.6583304088300987\n",
      "Epoch:111, w1:0.9569541110859784, w2:0.9051502509069093, bias:-0.2209692417467193, loss:0.657988413718373\n",
      "Epoch:112, w1:0.9566816842500014, w2:0.9044827250028097, bias:-0.22266163221965915, loss:0.6576484774643672\n",
      "Epoch:113, w1:0.9564110858836912, w2:0.903818157863448, bias:-0.224349450425337, loss:0.6573105886761362\n",
      "Epoch:114, w1:0.9561423117355454, w2:0.9031565431599154, bias:-0.2260327072212629, loss:0.6569747360017595\n",
      "Epoch:115, w1:0.9558753575492365, w2:0.9024978745474679, bias:-0.22771141347379964, loss:0.6566409081294786\n",
      "Epoch:116, w1:0.9556102190637557, w2:0.9018421456658093, bias:-0.22938558005781648, loss:0.6563090937878322\n",
      "Epoch:117, w1:0.9553468920135575, w2:0.901189350139375, bias:-0.23105521785634503, loss:0.6559792817457879\n",
      "Epoch:118, w1:0.9550853721287027, w2:0.900539481577612, bias:-0.23272033776023715, loss:0.6556514608128666\n",
      "Epoch:119, w1:0.9548256551350006, w2:0.8998925335752597, bias:-0.2343809506678251, loss:0.6553256198392682\n",
      "Epoch:120, w1:0.9545677367541507, w2:0.899248499712628, bias:-0.2360370674845838, loss:0.6550017477159865\n",
      "Epoch:121, w1:0.9543116127038835, w2:0.8986073735558753, bias:-0.23768869912279508, loss:0.6546798333749279\n",
      "Epoch:122, w1:0.9540572786981, w2:0.8979691486572837, bias:-0.23933585650121425, loss:0.6543598657890191\n",
      "Epoch:123, w1:0.953804730447011, w2:0.8973338185555343, bias:-0.2409785505447388, loss:0.6540418339723161\n",
      "Epoch:124, w1:0.9535539636572754, w2:0.89670137677598, bias:-0.24261679218407908, loss:0.653725726980107\n",
      "Epoch:125, w1:0.9533049740321372, w2:0.896071816830918, bias:-0.24425059235543145, loss:0.6534115339090117\n",
      "Epoch:126, w1:0.9530577572715622, w2:0.8954451322198596, bias:-0.24587996200015325, loss:0.6530992438970766\n",
      "Epoch:127, w1:0.9528123090723736, w2:0.8948213164298002, bias:-0.2475049120644402, loss:0.6527888461238679\n",
      "Epoch:128, w1:0.9525686251283869, w2:0.8942003629354868, bias:-0.24912545349900583, loss:0.6524803298105594\n",
      "Epoch:129, w1:0.9523267011305436, w2:0.8935822651996839, bias:-0.2507415972587632, loss:0.6521736842200165\n",
      "Epoch:130, w1:0.9520865327670447, w2:0.8929670166734391, bias:-0.25235335430250877, loss:0.651868898656879\n",
      "Epoch:131, w1:0.9518481157234824, w2:0.8923546107963467, bias:-0.2539607355926083, loss:0.6515659624676367\n",
      "Epoch:132, w1:0.9516114456829717, w2:0.8917450409968092, bias:-0.25556375209468524, loss:0.6512648650407047\n",
      "Epoch:133, w1:0.9513765183262812, w2:0.8911383006922986, bias:-0.257162414777311, loss:0.6509655958064932\n",
      "Epoch:134, w1:0.9511433293319623, w2:0.8905343832896155, bias:-0.25875673461169774, loss:0.6506681442374735\n",
      "Epoch:135, w1:0.9509118743764781, w2:0.889933282185147, bias:-0.260346722571393, loss:0.6503724998482444\n",
      "Epoch:136, w1:0.9506821491343311, w2:0.8893349907651227, bias:-0.26193238963197696, loss:0.6500786521955881\n",
      "Epoch:137, w1:0.9504541492781908, w2:0.88873950240587, bias:-0.2635137467707614, loss:0.6497865908785309\n",
      "Epoch:138, w1:0.9502278704790194, w2:0.8881468104740673, bias:-0.26509080496649123, loss:0.6494963055383933\n",
      "Epoch:139, w1:0.950003308406197, w2:0.8875569083269962, bias:-0.2666635751990482, loss:0.6492077858588421\n",
      "Epoch:140, w1:0.9497804587276464, w2:0.8869697893127916, bias:-0.26823206844915676, loss:0.6489210215659362\n",
      "Epoch:141, w1:0.9495593171099563, w2:0.8863854467706911, bias:-0.26979629569809194, loss:0.6486360024281702\n",
      "Epoch:142, w1:0.9493398792185042, w2:0.885803874031282, bias:-0.2713562679273898, loss:0.648352718256514\n",
      "Epoch:143, w1:0.9491221407175777, w2:0.885225064416748, bias:-0.2729119961185598, loss:0.6480711589044511\n",
      "Epoch:144, w1:0.9489060972704962, w2:0.884649011241113, bias:-0.27446349125279956, loss:0.6477913142680115\n",
      "Epoch:145, w1:0.9486917445397303, w2:0.8840757078104843, bias:-0.27601076431071164, loss:0.6475131742858028\n",
      "Epoch:146, w1:0.9484790781870207, w2:0.8835051474232943, bias:-0.2775538262720228, loss:0.6472367289390376\n",
      "Epoch:147, w1:0.9482680938734975, w2:0.8829373233705403, bias:-0.27909268811530524, loss:0.6469619682515583\n",
      "Epoch:148, w1:0.9480587872597965, w2:0.8823722289360227, bias:-0.2806273608177002, loss:0.6466888822898592\n",
      "Epoch:149, w1:0.9478511540061763, w2:0.8818098573965825, bias:-0.28215785535464344, loss:0.6464174611631036\n",
      "Epoch:150, w1:0.9476451897726336, w2:0.8812502020223358, bias:-0.2836841826995936, loss:0.6461476950231416\n",
      "Epoch:151, w1:0.9474408902190183, w2:0.8806932560769087, bias:-0.285206353823762, loss:0.6458795740645201\n",
      "Epoch:152, w1:0.947238251005147, w2:0.8801390128176688, bias:-0.2867243796958452, loss:0.6456130885244956\n",
      "Epoch:153, w1:0.9470372677909161, w2:0.8795874654959561, bias:-0.2882382712817594, loss:0.6453482286830391\n",
      "Epoch:154, w1:0.946837936236414, w2:0.8790386073573127, bias:-0.28974803954437733, loss:0.6450849848628405\n",
      "Epoch:155, w1:0.9466402520020321, w2:0.8784924316417098, bias:-0.2912536954432672, loss:0.6448233474293105\n",
      "Epoch:156, w1:0.9464442107485751, w2:0.8779489315837744, bias:-0.2927552499344337, loss:0.6445633067905793\n",
      "Epoch:157, w1:0.9462498081373709, w2:0.8774081004130138, bias:-0.29425271397006153, loss:0.6443048533974918\n",
      "Epoch:158, w1:0.9460570398303788, w2:0.8768699313540382, bias:-0.29574609849826083, loss:0.6440479777436012\n",
      "Epoch:159, w1:0.9458659014902971, w2:0.876334417626783, bias:-0.29723541446281493, loss:0.6437926703651596\n",
      "Epoch:160, w1:0.9456763887806702, w2:0.8758015524467277, bias:-0.29872067280293024, loss:0.6435389218411053\n",
      "Epoch:161, w1:0.9454884973659943, w2:0.8752713290251153, bias:-0.30020188445298834, loss:0.6432867227930484\n",
      "Epoch:162, w1:0.9453022229118225, w2:0.8747437405691683, bias:-0.30167906034230024, loss:0.6430360638852544\n",
      "Epoch:163, w1:0.9451175610848694, w2:0.8742187802823044, bias:-0.3031522113948628, loss:0.6427869358246225\n",
      "Epoch:164, w1:0.9449345075531138, w2:0.8736964413643503, bias:-0.3046213485291174, loss:0.6425393293606654\n",
      "Epoch:165, w1:0.9447530579859015, w2:0.8731767170117537, bias:-0.30608648265771055, loss:0.6422932352854827\n",
      "Epoch:166, w1:0.9445732080540467, w2:0.8726596004177937, bias:-0.307547624687257, loss:0.6420486444337347\n",
      "Epoch:167, w1:0.9443949534299327, w2:0.87214508477279, bias:-0.3090047855181047, loss:0.6418055476826127\n",
      "Epoch:168, w1:0.9442182897876122, w2:0.8716331632643103, bias:-0.310457976044102, loss:0.6415639359518066\n",
      "Epoch:169, w1:0.9440432128029055, w2:0.8711238290773764, bias:-0.31190720715236736, loss:0.6413238002034711\n",
      "Epoch:170, w1:0.9438697181534991, w2:0.8706170753946685, bias:-0.31335248972306023, loss:0.6410851314421886\n",
      "Epoch:171, w1:0.9436978015190427, w2:0.8701128953967275, bias:-0.31479383462915533, loss:0.6408479207149301\n",
      "Epoch:172, w1:0.9435274585812459, w2:0.8696112822621572, bias:-0.31623125273621805, loss:0.6406121591110151\n",
      "Epoch:173, w1:0.9433586850239732, w2:0.869112229167823, bias:-0.3176647549021825, loss:0.6403778377620667\n",
      "Epoch:174, w1:0.9431914765333393, w2:0.8686157292890506, bias:-0.31909435197713154, loss:0.6401449478419675\n",
      "Epoch:175, w1:0.9430258287978022, w2:0.8681217757998222, bias:-0.32052005480307894, loss:0.6399134805668102\n",
      "Epoch:176, w1:0.9428617375082564, w2:0.8676303618729718, bias:-0.3219418742137534, loss:0.6396834271948497\n",
      "Epoch:177, w1:0.9426991983581254, w2:0.8671414806803787, bias:-0.3233598210343853, loss:0.6394547790264496\n",
      "Epoch:178, w1:0.9425382070434524, w2:0.8666551253931589, bias:-0.3247739060814948, loss:0.6392275274040289\n",
      "Epoch:179, w1:0.9423787592629908, w2:0.8661712891818562, bias:-0.3261841401626825, loss:0.6390016637120054\n",
      "Epoch:180, w1:0.9422208507182938, w2:0.8656899652166302, bias:-0.3275905340764219, loss:0.6387771793767386\n",
      "Epoch:181, w1:0.9420644771138031, w2:0.8652111466674443, bias:-0.32899309861185444, loss:0.6385540658664685\n",
      "Epoch:182, w1:0.9419096341569371, w2:0.8647348267042506, bias:-0.3303918445485859, loss:0.6383323146912544\n",
      "Epoch:183, w1:0.9417563175581769, w2:0.8642609984971751, bias:-0.3317867826564853, loss:0.638111917402911\n",
      "Epoch:184, w1:0.9416045230311537, w2:0.8637896552166993, bias:-0.33317792369548593, loss:0.6378928655949422\n",
      "Epoch:185, w1:0.9414542462927333, w2:0.863320790033842, bias:-0.33456527841538797, loss:0.6376751509024735\n",
      "Epoch:186, w1:0.941305483063101, w2:0.8628543961203385, bias:-0.3359488575556638, loss:0.6374587650021833\n",
      "Epoch:187, w1:0.9411582290658451, w2:0.862390466648819, bias:-0.3373286718452646, loss:0.6372436996122303\n",
      "Epoch:188, w1:0.9410124800280398, w2:0.8619289947929845, bias:-0.33870473200242973, loss:0.6370299464921813\n",
      "Epoch:189, w1:0.9408682316803272, w2:0.8614699737277822, bias:-0.34007704873449746, loss:0.6368174974429374\n",
      "Epoch:190, w1:0.9407254797569986, w2:0.861013396629579, bias:-0.34144563273771816, loss:0.6366063443066544\n",
      "Epoch:191, w1:0.9405842199960748, w2:0.8605592566763333, bias:-0.3428104946970693, loss:0.6363964789666686\n",
      "Epoch:192, w1:0.9404444481393857, w2:0.8601075470477653, bias:-0.3441716452860726, loss:0.636187893347414\n",
      "Epoch:193, w1:0.940306159932649, w2:0.8596582609255261, bias:-0.3455290951666127, loss:0.6359805794143417\n",
      "Epoch:194, w1:0.9401693511255482, w2:0.8592113914933651, bias:-0.34688285498875854, loss:0.6357745291738368\n",
      "Epoch:195, w1:0.9400340174718099, w2:0.8587669319372958, bias:-0.34823293539058614, loss:0.6355697346731349\n",
      "Epoch:196, w1:0.9399001547292797, w2:0.8583248754457602, bias:-0.3495793469980035, loss:0.6353661880002337\n",
      "Epoch:197, w1:0.9397677586599982, w2:0.8578852152097917, bias:-0.3509221004245776, loss:0.6351638812838067\n",
      "Epoch:198, w1:0.9396368250302755, w2:0.8574479444231765, bias:-0.35226120627136304, loss:0.634962806693114\n",
      "Epoch:199, w1:0.939507349610765, w2:0.8570130562826137, bias:-0.35359667512673293, loss:0.6347629564379109\n",
      "Epoch:200, w1:0.939379328176537, w2:0.8565805439878733, bias:-0.3549285175662115, loss:0.6345643227683564\n",
      "Epoch:201, w1:0.9392527565071507, w2:0.8561504007419537, bias:-0.3562567441523088, loss:0.6343668979749192\n",
      "Epoch:202, w1:0.9391276303867258, w2:0.8557226197512368, bias:-0.35758136543435703, loss:0.6341706743882828\n",
      "Epoch:203, w1:0.9390039456040133, w2:0.855297194225642, bias:-0.3589023919483491, loss:0.6339756443792498\n",
      "Epoch:204, w1:0.9388816979524659, w2:0.854874117378779, bias:-0.36021983421677883, loss:0.6337818003586431\n",
      "Epoch:205, w1:0.9387608832303066, w2:0.8544533824280989, bias:-0.3615337027484832, loss:0.633589134777208\n",
      "Epoch:206, w1:0.9386414972405975, w2:0.8540349825950432, bias:-0.3628440080384863, loss:0.6333976401255114\n",
      "Epoch:207, w1:0.9385235357913078, w2:0.8536189111051928, bias:-0.3641507605678455, loss:0.63320730893384\n",
      "Epoch:208, w1:0.9384069946953799, w2:0.8532051611884144, bias:-0.3654539708034988, loss:0.6330181337720983\n",
      "Epoch:209, w1:0.9382918697707967, w2:0.8527937260790054, bias:-0.3667536491981147, loss:0.6328301072497046\n",
      "Epoch:210, w1:0.938178156840646, w2:0.8523845990158385, bias:-0.3680498061899438, loss:0.6326432220154841\n",
      "Epoch:211, w1:0.9380658517331857, w2:0.8519777732425036, bias:-0.36934245220267176, loss:0.6324574707575651\n",
      "Epoch:212, w1:0.9379549502819077, w2:0.8515732420074488, bias:-0.3706315976452745, loss:0.6322728462032697\n",
      "Epoch:213, w1:0.9378454483256008, w2:0.8511709985641202, bias:-0.37191725291187516, loss:0.632089341119006\n",
      "Epoch:214, w1:0.9377373417084135, w2:0.8507710361710998, bias:-0.3731994283816028, loss:0.6319069483101583\n",
      "Epoch:215, w1:0.9376306262799152, w2:0.8503733480922429, bias:-0.37447813441845285, loss:0.6317256606209756\n",
      "Epoch:216, w1:0.9375252978951577, w2:0.8499779275968123, bias:-0.3757533813711493, loss:0.6315454709344607\n",
      "Epoch:217, w1:0.9374213524147349, w2:0.8495847679596136, bias:-0.37702517957300874, loss:0.6313663721722569\n",
      "Epoch:218, w1:0.9373187857048426, w2:0.8491938624611264, bias:-0.3782935393418064, loss:0.6311883572945347\n",
      "Epoch:219, w1:0.9372175936373373, w2:0.8488052043876366, bias:-0.3795584709796433, loss:0.6310114192998757\n",
      "Epoch:220, w1:0.9371177720897937, w2:0.8484187870313658, bias:-0.38081998477281587, loss:0.6308355512251578\n",
      "Epoch:221, w1:0.9370193169455632, w2:0.8480346036905992, bias:-0.38207809099168677, loss:0.6306607461454384\n",
      "Epoch:222, w1:0.936922224093829, w2:0.8476526476698137, bias:-0.3833327998905576, loss:0.6304869971738365\n",
      "Epoch:223, w1:0.9368264894296632, w2:0.8472729122798028, bias:-0.3845841217075433, loss:0.6303142974614139\n",
      "Epoch:224, w1:0.9367321088540813, w2:0.8468953908378011, bias:-0.38583206666444864, loss:0.6301426401970563\n",
      "Epoch:225, w1:0.9366390782740972, w2:0.8465200766676072, bias:-0.3870766449666455, loss:0.6299720186073531\n",
      "Epoch:226, w1:0.9365473936027766, w2:0.8461469630997059, bias:-0.3883178668029528, loss:0.6298024259564747\n",
      "Epoch:227, w1:0.9364570507592903, w2:0.845776043471388, bias:-0.3895557423455175, loss:0.6296338555460532\n",
      "Epoch:228, w1:0.9363680456689665, w2:0.8454073111268692, bias:-0.3907902817496974, loss:0.6294663007150578\n",
      "Epoch:229, w1:0.9362803742633424, w2:0.845040759417408, bias:-0.39202149515394563, loss:0.6292997548396713\n",
      "Epoch:230, w1:0.9361940324802159, w2:0.844676381701422, bias:-0.39324939267969694, loss:0.629134211333167\n",
      "Epoch:231, w1:0.9361090162636951, w2:0.8443141713446031, bias:-0.3944739844312552, loss:0.6289696636457828\n",
      "Epoch:232, w1:0.9360253215642484, w2:0.8439541217200307, bias:-0.39569528049568287, loss:0.6288061052645959\n",
      "Epoch:233, w1:0.9359429443387538, w2:0.8435962262082847, bias:-0.396913290942692, loss:0.6286435297133962\n",
      "Epoch:234, w1:0.9358618805505466, w2:0.8432404781975562, bias:-0.3981280258245368, loss:0.6284819305525601\n",
      "Epoch:235, w1:0.9357821261694677, w2:0.8428868710837578, bias:-0.3993394951759078, loss:0.6283213013789205\n",
      "Epoch:236, w1:0.9357036771719102, w2:0.8425353982706317, bias:-0.40054770901382736, loss:0.6281616358256419\n",
      "Epoch:237, w1:0.9356265295408661, w2:0.8421860531698573, bias:-0.4017526773375474, loss:0.6280029275620888\n",
      "Epoch:238, w1:0.9355506792659719, w2:0.8418388292011569, bias:-0.4029544101284479, loss:0.6278451702936962\n",
      "Epoch:239, w1:0.9354761223435536, w2:0.8414937197924012, bias:-0.4041529173499375, loss:0.6276883577618422\n",
      "Epoch:240, w1:0.9354028547766712, w2:0.8411507183797118, bias:-0.4053482089473554, loss:0.6275324837437137\n",
      "Epoch:241, w1:0.9353308725751626, w2:0.8408098184075643, bias:-0.4065402948478747, loss:0.6273775420521776\n",
      "Epoch:242, w1:0.9352601717556867, w2:0.8404710133288891, bias:-0.4077291849604075, loss:0.6272235265356485\n",
      "Epoch:243, w1:0.9351907483417659, w2:0.840134296605171, bias:-0.40891488917551144, loss:0.6270704310779557\n",
      "Epoch:244, w1:0.9351225983638279, w2:0.8397996617065482, bias:-0.41009741736529753, loss:0.6269182495982119\n",
      "Epoch:245, w1:0.9350557178592476, w2:0.8394671021119092, bias:-0.4112767793833398, loss:0.6267669760506783\n",
      "Epoch:246, w1:0.9349901028723867, w2:0.8391366113089894, bias:-0.41245298506458605, loss:0.6266166044246323\n",
      "Epoch:247, w1:0.9349257494546348, w2:0.8388081827944658, bias:-0.41362604422527044, loss:0.6264671287442332\n",
      "Epoch:248, w1:0.9348626536644482, w2:0.8384818100740508, bias:-0.4147959666628272, loss:0.6263185430683863\n",
      "Epoch:249, w1:0.9348008115673893, w2:0.8381574866625847, bias:-0.41596276215580597, loss:0.6261708414906102\n",
      "Epoch:250, w1:0.934740219236164, w2:0.8378352060841275, bias:-0.41712644046378866, loss:0.6260240181388996\n",
      "Epoch:251, w1:0.9346808727506604, w2:0.8375149618720485, bias:-0.41828701132730745, loss:0.6258780671755908\n",
      "Epoch:252, w1:0.9346227681979848, w2:0.837196747569116, bias:-0.4194444844677644, loss:0.6257329827972244\n",
      "Epoch:253, w1:0.9345659016724993, w2:0.8368805567275847, bias:-0.4205988695873525, loss:0.6255887592344107\n",
      "Epoch:254, w1:0.9345102692758566, w2:0.8365663829092825, bias:-0.42175017636897794, loss:0.6254453907516914\n",
      "Epoch:255, w1:0.9344558671170357, w2:0.8362542196856965, bias:-0.4228984144761839, loss:0.6253028716474028\n",
      "Epoch:256, w1:0.934402691312377, w2:0.8359440606380569, bias:-0.4240435935530758, loss:0.6251611962535395\n",
      "Epoch:257, w1:0.934350737985616, w2:0.8356358993574208, bias:-0.42518572322424747, loss:0.6250203589356156\n",
      "Epoch:258, w1:0.934300003267917, w2:0.835329729444754, bias:-0.42632481309470927, loss:0.6248803540925275\n",
      "Epoch:259, w1:0.9342504832979062, w2:0.8350255445110124, bias:-0.4274608727498171, loss:0.6247411761564153\n",
      "Epoch:260, w1:0.9342021742217039, w2:0.8347233381772219, bias:-0.428593911755203, loss:0.6246028195925253\n",
      "Epoch:261, w1:0.9341550721929569, w2:0.834423104074557, bias:-0.429723939656707, loss:0.62446527889907\n",
      "Epoch:262, w1:0.9341091733728693, w2:0.834124835844419, bias:-0.4308509659803101, loss:0.6243285486070905\n",
      "Epoch:263, w1:0.9340644739302334, w2:0.8338285271385124, bias:-0.4319750002320688, loss:0.6241926232803173\n",
      "Epoch:264, w1:0.9340209700414605, w2:0.8335341716189205, bias:-0.43309605189805095, loss:0.6240574975150305\n",
      "Epoch:265, w1:0.9339786578906096, w2:0.8332417629581802, bias:-0.4342141304442725, loss:0.6239231659399208\n",
      "Epoch:266, w1:0.9339375336694179, w2:0.832951294839355, bias:-0.4353292453166359, loss:0.6237896232159502\n",
      "Epoch:267, w1:0.9338975935773282, w2:0.8326627609561079, bias:-0.4364414059408698, loss:0.6236568640362122\n",
      "Epoch:268, w1:0.9338588338215176, w2:0.8323761550127724, bias:-0.4375506217224695, loss:0.623524883125792\n",
      "Epoch:269, w1:0.9338212506169252, w2:0.8320914707244229, bias:-0.4386569020466393, loss:0.623393675241626\n",
      "Epoch:270, w1:0.9337848401862789, w2:0.8318087018169441, bias:-0.43976025627823556, loss:0.623263235172363\n",
      "Epoch:271, w1:0.9337495987601222, w2:0.831527842027099, bias:-0.4408606937617112, loss:0.6231335577382231\n",
      "Epoch:272, w1:0.9337155225768398, w2:0.8312488851025962, bias:-0.4419582238210615, loss:0.6230046377908575\n",
      "Epoch:273, w1:0.9336826078826835, w2:0.8309718248021563, bias:-0.4430528557597708, loss:0.6228764702132091\n",
      "Epoch:274, w1:0.9336508509317974, w2:0.8306966548955768, bias:-0.44414459886076085, loss:0.6227490499193712\n",
      "Epoch:275, w1:0.9336202479862421, w2:0.8304233691637962, bias:-0.44523346238633976, loss:0.6226223718544477\n",
      "Epoch:276, w1:0.9335907953160187, w2:0.8301519613989577, bias:-0.44631945557815267, loss:0.6224964309944125\n",
      "Epoch:277, w1:0.9335624891990927, w2:0.829882425404471, bias:-0.4474025876571332, loss:0.622371222345969\n",
      "Epoch:278, w1:0.9335353259214165, w2:0.8296147549950732, bias:-0.44848286782345625, loss:0.6222467409464097\n",
      "Epoch:279, w1:0.9335093017769527, w2:0.8293489439968899, bias:-0.44956030525649193, loss:0.6221229818634763\n",
      "Epoch:280, w1:0.9334844130676955, w2:0.8290849862474937, bias:-0.45063490911476045, loss:0.6219999401952178\n",
      "Epoch:281, w1:0.9334606561036927, w2:0.828822875595963, bias:-0.45170668853588836, loss:0.6218776110698515\n",
      "Epoch:282, w1:0.9334380272030667, w2:0.8285626059029391, bias:-0.4527756526365658, loss:0.6217559896456225\n",
      "Epoch:283, w1:0.9334165226920352, w2:0.8283041710406825, bias:-0.4538418105125048, loss:0.6216350711106623\n",
      "Epoch:284, w1:0.9333961389049316, w2:0.828047564893129, bias:-0.4549051712383988, loss:0.6215148506828497\n",
      "Epoch:285, w1:0.9333768721842243, w2:0.8277927813559434, bias:-0.45596574386788313, loss:0.6213953236096695\n",
      "Epoch:286, w1:0.9333587188805363, w2:0.8275398143365736, bias:-0.4570235374334966, loss:0.6212764851680735\n",
      "Epoch:287, w1:0.9333416753526642, w2:0.8272886577543035, bias:-0.4580785609466443, loss:0.6211583306643391\n",
      "Epoch:288, w1:0.9333257379675962, w2:0.8270393055403042, bias:-0.45913082339756106, loss:0.6210408554339303\n",
      "Epoch:289, w1:0.9333109031005301, w2:0.8267917516376856, bias:-0.46018033375527656, loss:0.6209240548413569\n",
      "Epoch:290, w1:0.9332971671348911, w2:0.8265459900015456, bias:-0.46122710096758096, loss:0.6208079242800361\n",
      "Epoch:291, w1:0.9332845264623486, w2:0.82630201459902, bias:-0.4622711339609918, loss:0.6206924591721509\n",
      "Epoch:292, w1:0.9332729774828328, w2:0.82605981940933, bias:-0.46331244164072166, loss:0.6205776549685127\n",
      "Epoch:293, w1:0.9332625166045511, w2:0.8258193984238303, bias:-0.4643510328906474, loss:0.6204635071484196\n",
      "Epoch:294, w1:0.9332531402440035, w2:0.8255807456460549, bias:-0.46538691657327974, loss:0.6203500112195187\n",
      "Epoch:295, w1:0.9332448448259986, w2:0.8253438550917629, bias:-0.4664201015297342, loss:0.6202371627176668\n",
      "Epoch:296, w1:0.9332376267836677, w2:0.8251087207889836, bias:-0.46745059657970295, loss:0.6201249572067911\n",
      "Epoch:297, w1:0.93323148255848, w2:0.82487533677806, bias:-0.4684784105214277, loss:0.6200133902787495\n",
      "Epoch:298, w1:0.9332264086002561, w2:0.8246436971116923, bias:-0.4695035521316733, loss:0.6199024575531937\n",
      "Epoch:299, w1:0.9332224013671823, w2:0.8244137958549794, bias:-0.47052603016570266, loss:0.6197921546774302\n",
      "Epoch:300, w1:0.9332194573258233, w2:0.8241856270854614, bias:-0.4715458533572524, loss:0.6196824773262809\n",
      "Epoch:301, w1:0.9332175729511357, w2:0.823959184893159, bias:-0.4725630304185094, loss:0.6195734212019466\n",
      "Epoch:302, w1:0.9332167447264798, w2:0.8237344633806142, bias:-0.47357757004008827, loss:0.6194649820338681\n",
      "Epoch:303, w1:0.9332169691436321, w2:0.8235114566629287, bias:-0.4745894808910101, loss:0.6193571555785888\n",
      "Epoch:304, w1:0.933218242702797, w2:0.8232901588678025, bias:-0.4755987716186816, loss:0.6192499376196179\n",
      "Epoch:305, w1:0.933220561912618, w2:0.823070564135571, bias:-0.47660545084887534, loss:0.6191433239672919\n",
      "Epoch:306, w1:0.9332239232901888, w2:0.8228526666192416, bias:-0.4776095271857112, loss:0.6190373104586392\n",
      "Epoch:307, w1:0.9332283233610634, w2:0.8226364604845295, bias:-0.4786110092116382, loss:0.618931892957242\n",
      "Epoch:308, w1:0.9332337586592668, w2:0.822421939909893, bias:-0.4796099054874174, loss:0.618827067353101\n",
      "Epoch:309, w1:0.9332402257273046, w2:0.8222090990865673, bias:-0.480606224552106, loss:0.6187228295624982\n",
      "Epoch:310, w1:0.9332477211161722, w2:0.8219979322185983, bias:-0.4815999749230417, loss:0.6186191755278616\n",
      "Epoch:311, w1:0.9332562413853641, w2:0.8217884335228754, bias:-0.4825911650958283, loss:0.6185161012176292\n",
      "Epoch:312, w1:0.9332657831028829, w2:0.8215805972291635, bias:-0.48357980354432206, loss:0.6184136026261134\n",
      "Epoch:313, w1:0.933276342845247, w2:0.821374417580134, bias:-0.48456589872061906, loss:0.618311675773367\n",
      "Epoch:314, w1:0.9332879171974988, w2:0.8211698888313952, bias:-0.48554945905504293, loss:0.6182103167050463\n",
      "Epoch:315, w1:0.9333005027532129, w2:0.8209670052515229, bias:-0.48653049295613393, loss:0.618109521492279\n",
      "Epoch:316, w1:0.9333140961145023, w2:0.8207657611220888, bias:-0.48750900881063836, loss:0.6180092862315276\n",
      "Epoch:317, w1:0.9333286938920266, w2:0.8205661507376887, bias:-0.4884850149834993, loss:0.6179096070444572\n",
      "Epoch:318, w1:0.9333442927049973, w2:0.8203681684059708, bias:-0.4894585198178475, loss:0.617810480077801\n",
      "Epoch:319, w1:0.9333608891811853, w2:0.8201718084476622, bias:-0.49042953163499375, loss:0.6177119015032273\n",
      "Epoch:320, w1:0.933378479956926, w2:0.8199770651965953, bias:-0.4913980587344215, loss:0.6176138675172061\n",
      "Epoch:321, w1:0.9333970616771251, w2:0.8197839329997332, bias:-0.49236410939378034, loss:0.6175163743408772\n",
      "Epoch:322, w1:0.933416630995264, w2:0.8195924062171945, bias:-0.49332769186888054, loss:0.6174194182199165\n",
      "Epoch:323, w1:0.9334371845734044, w2:0.8194024792222782, bias:-0.49428881439368805, loss:0.617322995424406\n",
      "Epoch:324, w1:0.9334587190821935, w2:0.819214146401486, bias:-0.4952474851803203, loss:0.6172271022486996\n",
      "Epoch:325, w1:0.9334812312008676, w2:0.8190274021545465, bias:-0.49620371241904276, loss:0.6171317350112941\n",
      "Epoch:326, w1:0.9335047176172567, w2:0.8188422408944362, bias:-0.49715750427826627, loss:0.6170368900546969\n",
      "Epoch:327, w1:0.9335291750277879, w2:0.818658657047402, bias:-0.4981088689045451, loss:0.6169425637452955\n",
      "Epoch:328, w1:0.9335546001374886, w2:0.8184766450529816, bias:-0.4990578144225756, loss:0.6168487524732277\n",
      "Epoch:329, w1:0.9335809896599897, w2:0.8182961993640234, bias:-0.5000043489351956, loss:0.6167554526522511\n",
      "Epoch:330, w1:0.9336083403175286, w2:0.8181173144467072, bias:-0.5009484805233849, loss:0.6166626607196138\n",
      "Epoch:331, w1:0.9336366488409511, w2:0.8179399847805621, bias:-0.5018902172462655, loss:0.6165703731359264\n",
      "Epoch:332, w1:0.933665911969714, w2:0.8177642048584853, bias:-0.5028295671411036, loss:0.6164785863850305\n",
      "Epoch:333, w1:0.933696126451887, w2:0.8175899691867602, bias:-0.5037665382233116, loss:0.6163872969738726\n",
      "Epoch:334, w1:0.9337272890441539, w2:0.8174172722850728, bias:-0.5047011384864512, loss:0.6162965014323758\n",
      "Epoch:335, w1:0.9337593965118139, w2:0.8172461086865287, bias:-0.5056333759022363, loss:0.6162061963133109\n",
      "Epoch:336, w1:0.9337924456287832, w2:0.8170764729376689, bias:-0.5065632584205382, loss:0.6161163781921701\n",
      "Epoch:337, w1:0.9338264331775948, w2:0.8169083595984854, bias:-0.5074907939693892, loss:0.6160270436670403\n",
      "Epoch:338, w1:0.9338613559493999, w2:0.8167417632424354, bias:-0.5084159904549892, loss:0.6159381893584762\n",
      "Epoch:339, w1:0.9338972107439673, w2:0.816576678456456, bias:-0.509338855761711, loss:0.6158498119093742\n",
      "Epoch:340, w1:0.9339339943696834, w2:0.8164130998409773, bias:-0.5102593977521075, loss:0.6157619079848463\n",
      "Epoch:341, w1:0.9339717036435523, w2:0.8162510220099358, bias:-0.5111776242669188, loss:0.615674474272097\n",
      "Epoch:342, w1:0.9340103353911947, w2:0.8160904395907868, bias:-0.5120935431250803, loss:0.6155875074802953\n",
      "Epoch:343, w1:0.934049886446847, w2:0.8159313472245159, bias:-0.513007162123731, loss:0.6155010043404524\n",
      "Epoch:344, w1:0.9340903536533605, w2:0.8157737395656508, bias:-0.5139184890382231, loss:0.6154149616052974\n",
      "Epoch:345, w1:0.9341317338621993, w2:0.815617611282272, bias:-0.5148275316221315, loss:0.6153293760491529\n",
      "Epoch:346, w1:0.9341740239334394, w2:0.8154629570560226, bias:-0.5157342976072639, loss:0.6152442444678128\n",
      "Epoch:347, w1:0.9342172207357662, w2:0.8153097715821186, bias:-0.5166387947036721, loss:0.6151595636784187\n",
      "Epoch:348, w1:0.9342613211464724, w2:0.8151580495693577, bias:-0.5175410305996637, loss:0.6150753305193383\n",
      "Epoch:349, w1:0.9343063220514558, w2:0.8150077857401279, bias:-0.5184410129618132, loss:0.614991541850043\n",
      "Epoch:350, w1:0.9343522203452164, w2:0.8148589748304159, bias:-0.5193387494349757, loss:0.6149081945509868\n",
      "Epoch:351, w1:0.9343990129308534, w2:0.8147116115898144, bias:-0.5202342476422993, loss:0.6148252855234848\n",
      "Epoch:352, w1:0.9344466967200623, w2:0.8145656907815293, bias:-0.5211275151852391, loss:0.6147428116895933\n",
      "Epoch:353, w1:0.9344952686331314, w2:0.8144212071823863, bias:-0.5220185596435717, loss:0.6146607699919889\n",
      "Epoch:354, w1:0.934544725598938, w2:0.814278155582837, bias:-0.5229073885754093, loss:0.6145791573938495\n",
      "Epoch:355, w1:0.9345950645549447, w2:0.8141365307869644, bias:-0.5237940095172157, loss:0.6144979708787347\n",
      "Epoch:356, w1:0.9346462824471952, w2:0.8139963276124879, bias:-0.5246784299838215, loss:0.6144172074504664\n",
      "Epoch:357, w1:0.9346983762303102, w2:0.8138575408907681, bias:-0.5255606574684413, loss:0.6143368641330118\n",
      "Epoch:358, w1:0.9347513428674826, w2:0.8137201654668109, bias:-0.5264406994426895, loss:0.6142569379703641\n",
      "Epoch:359, w1:0.934805179330473, w2:0.813584196199271, bias:-0.5273185633565982, loss:0.614177426026426\n",
      "Epoch:360, w1:0.9348598825996044, w2:0.8134496279604553, bias:-0.5281942566386353, loss:0.6140983253848923\n",
      "Epoch:361, w1:0.9349154496637572, w2:0.813316455636325, bias:-0.5290677866957221, loss:0.6140196331491331\n",
      "Epoch:362, w1:0.9349718775203638, w2:0.813184674126499, bias:-0.5299391609132527, loss:0.6139413464420781\n",
      "Epoch:363, w1:0.935029163175403, w2:0.8130542783442544, bias:-0.530808386655113, loss:0.613863462406101\n",
      "Epoch:364, w1:0.9350873036433939, w2:0.8129252632165287, bias:-0.5316754712637006, loss:0.6137859782029037\n",
      "Epoch:365, w1:0.9351462959473904, w2:0.8127976236839204, bias:-0.5325404220599449, loss:0.6137088910134026\n",
      "Epoch:366, w1:0.9352061371189745, w2:0.8126713547006895, bias:-0.5334032463433277, loss:0.613632198037613\n",
      "Epoch:367, w1:0.93526682419825, w2:0.8125464512347575, bias:-0.5342639513919046, loss:0.6135558964945372\n",
      "Epoch:368, w1:0.9353283542338361, w2:0.8124229082677069, bias:-0.5351225444623264, loss:0.6134799836220486\n",
      "Epoch:369, w1:0.93539072428286, w2:0.8123007207947804, bias:-0.535979032789861, loss:0.613404456676781\n",
      "Epoch:370, w1:0.9354539314109506, w2:0.8121798838248799, bias:-0.5368334235884161, loss:0.6133293129340159\n",
      "Epoch:371, w1:0.9355179726922307, w2:0.8120603923805644, bias:-0.5376857240505619, loss:0.6132545496875692\n",
      "Epoch:372, w1:0.93558284520931, w2:0.8119422414980481, bias:-0.5385359413475543, loss:0.6131801642496811\n",
      "Epoch:373, w1:0.9356485460532773, w2:0.8118254262271979, bias:-0.539384082629359, loss:0.6131061539509052\n",
      "Epoch:374, w1:0.9357150723236929, w2:0.8117099416315304, bias:-0.5402301550246753, loss:0.6130325161399964\n",
      "Epoch:375, w1:0.9357824211285803, w2:0.811595782788209, bias:-0.5410741656409607, loss:0.6129592481838025\n",
      "Epoch:376, w1:0.9358505895844186, w2:0.8114829447880395, bias:-0.5419161215644558, loss:0.6128863474671543\n",
      "Epoch:377, w1:0.9359195748161337, w2:0.8113714227354665, bias:-0.5427560298602099, loss:0.6128138113927561\n",
      "Epoch:378, w1:0.9359893739570903, w2:0.8112612117485688, bias:-0.5435938975721064, loss:0.6127416373810768\n",
      "Epoch:379, w1:0.9360599841490824, w2:0.8111523069590546, bias:-0.5444297317228892, loss:0.6126698228702424\n",
      "Epoch:380, w1:0.9361314025423259, w2:0.8110447035122561, bias:-0.545263539314189, loss:0.6125983653159284\n",
      "Epoch:381, w1:0.9362036262954481, w2:0.8109383965671241, bias:-0.5460953273265501, loss:0.612527262191252\n",
      "Epoch:382, w1:0.9362766525754795, w2:0.8108333812962217, bias:-0.5469251027194578, loss:0.6124565109866654\n",
      "Epoch:383, w1:0.9363504785578443, w2:0.8107296528857185, bias:-0.5477528724313661, loss:0.6123861092098507\n",
      "Epoch:384, w1:0.9364251014263505, w2:0.8106272065353833, bias:-0.5485786433797253, loss:0.6123160543856124\n",
      "Epoch:385, w1:0.936500518373181, w2:0.8105260374585774, bias:-0.5494024224610108, loss:0.6122463440557736\n",
      "Epoch:386, w1:0.9365767265988831, w2:0.8104261408822472, bias:-0.5502242165507514, loss:0.6121769757790699\n",
      "Epoch:387, w1:0.936653723312359, w2:0.8103275120469161, bias:-0.5510440325035583, loss:0.6121079471310469\n",
      "Epoch:388, w1:0.9367315057308554, w2:0.8102301462066769, bias:-0.5518618771531548, loss:0.6120392557039535\n",
      "Epoch:389, w1:0.9368100710799535, w2:0.810134038629183, bias:-0.5526777573124058, loss:0.6119708991066418\n",
      "Epoch:390, w1:0.9368894165935585, w2:0.8100391845956396, bias:-0.5534916797733475, loss:0.6119028749644618\n",
      "Epoch:391, w1:0.936969539513889, w2:0.8099455794007951, bias:-0.5543036513072183, loss:0.6118351809191602\n",
      "Epoch:392, w1:0.9370504370914662, w2:0.809853218352931, bias:-0.555113678664489, loss:0.6117678146287774\n",
      "Epoch:393, w1:0.9371321065851036, w2:0.8097620967738526, bias:-0.5559217685748943, loss:0.6117007737675476\n",
      "Epoch:394, w1:0.9372145452618953, w2:0.8096722099988786, bias:-0.5567279277474634, loss:0.6116340560257961\n",
      "Epoch:395, w1:0.9372977503972054, w2:0.8095835533768311, bias:-0.5575321628705522, loss:0.6115676591098403\n",
      "Epoch:396, w1:0.9373817192746565, w2:0.8094961222700245, bias:-0.558334480611875, loss:0.6115015807418887\n",
      "Epoch:397, w1:0.9374664491861183, w2:0.8094099120542549, bias:-0.5591348876185365, loss:0.6114358186599413\n",
      "Epoch:398, w1:0.9375519374316964, w2:0.8093249181187885, bias:-0.5599333905170646, loss:0.611370370617692\n",
      "Epoch:399, w1:0.9376381813197202, w2:0.8092411358663498, bias:-0.560729995913443, loss:0.6113052343844275\n",
      "Epoch:400, w1:0.9377251781667315, w2:0.8091585607131104, bias:-0.5615247103931441, loss:0.6112404077449316\n",
      "Epoch:401, w1:0.9378129252974724, w2:0.8090771880886762, bias:-0.562317540521163, loss:0.6111758884993864\n",
      "Epoch:402, w1:0.9379014200448731, w2:0.808997013436075, bias:-0.5631084928420502, loss:0.6111116744632753\n",
      "Epoch:403, w1:0.9379906597500403, w2:0.8089180322117437, bias:-0.5638975738799462, loss:0.6110477634672861\n",
      "Epoch:404, w1:0.9380806417622441, w2:0.8088402398855157, bias:-0.5646847901386154, loss:0.6109841533572152\n",
      "Epoch:405, w1:0.9381713634389067, w2:0.808763631940607, bias:-0.5654701481014803, loss:0.6109208419938714\n",
      "Epoch:406, w1:0.9382628221455888, w2:0.8086882038736029, bias:-0.5662536542316566, loss:0.610857827252982\n",
      "Epoch:407, w1:0.9383550152559774, w2:0.8086139511944439, bias:-0.567035314971988, loss:0.6107951070250959\n",
      "Epoch:408, w1:0.9384479401518734, w2:0.808540869426412, bias:-0.567815136745081, loss:0.6107326792154909\n",
      "Epoch:409, w1:0.9385415942231781, w2:0.8084689541061159, bias:-0.5685931259533409, loss:0.6106705417440792\n",
      "Epoch:410, w1:0.9386359748678808, w2:0.8083982007834764, bias:-0.5693692889790071, loss:0.6106086925453144\n",
      "Epoch:411, w1:0.9387310794920454, w2:0.8083286050217114, bias:-0.570143632184189, loss:0.6105471295680985\n",
      "Epoch:412, w1:0.9388269055097972, w2:0.8082601623973213, bias:-0.5709161619109022, loss:0.6104858507756893\n",
      "Epoch:413, w1:0.9389234503433098, w2:0.8081928685000728, bias:-0.5716868844811052, loss:0.6104248541456085\n",
      "Epoch:414, w1:0.9390207114227916, w2:0.8081267189329835, bias:-0.5724558061967353, loss:0.6103641376695506\n",
      "Epoch:415, w1:0.9391186861864723, w2:0.8080617093123063, bias:-0.573222933339746, loss:0.6103036993532914\n",
      "Epoch:416, w1:0.9392173720805893, w2:0.8079978352675128, bias:-0.573988272172144, loss:0.6102435372165982\n",
      "Epoch:417, w1:0.9393167665593739, w2:0.8079350924412774, bias:-0.5747518289360258, loss:0.6101836492931386\n",
      "Epoch:418, w1:0.9394168670850377, w2:0.8078734764894602, bias:-0.5755136098536161, loss:0.6101240336303921\n",
      "Epoch:419, w1:0.9395176711277586, w2:0.8078129830810904, bias:-0.5762736211273046, loss:0.6100646882895604\n",
      "Epoch:420, w1:0.9396191761656669, w2:0.8077536078983492, bias:-0.5770318689396846, loss:0.6100056113454784\n",
      "Epoch:421, w1:0.939721379684831, w2:0.8076953466365524, bias:-0.5777883594535905, loss:0.609946800886527\n",
      "Epoch:422, w1:0.9398242791792435, w2:0.8076381950041333, bias:-0.5785430988121364, loss:0.6098882550145442\n",
      "Epoch:423, w1:0.9399278721508066, w2:0.8075821487226241, bias:-0.5792960931387542, loss:0.6098299718447392\n",
      "Epoch:424, w1:0.9400321561093182, w2:0.807527203526639, bias:-0.5800473485372328, loss:0.6097719495056038\n",
      "Epoch:425, w1:0.9401371285724571, w2:0.8074733551638551, bias:-0.5807968710917565, loss:0.6097141861388278\n",
      "Epoch:426, w1:0.9402427870657687, w2:0.8074205993949947, bias:-0.5815446668669438, loss:0.6096566798992126\n",
      "Epoch:427, w1:0.94034912912265, w2:0.8073689319938063, bias:-0.5822907419078873, loss:0.6095994289545849\n",
      "Epoch:428, w1:0.9404561522843355, w2:0.8073183487470463, bias:-0.5830351022401925, loss:0.6095424314857124\n",
      "Epoch:429, w1:0.9405638540998822, w2:0.8072688454544594, bias:-0.5837777538700174, loss:0.6094856856862201\n",
      "Epoch:430, w1:0.9406722321261543, w2:0.8072204179287599, bias:-0.5845187027841122, loss:0.6094291897625048\n",
      "Epoch:431, w1:0.9407812839278088, w2:0.8071730619956121, bias:-0.5852579549498595, loss:0.6093729419336525\n",
      "Epoch:432, w1:0.9408910070772806, w2:0.807126773493611, bias:-0.5859955163153139, loss:0.6093169404313546\n",
      "Epoch:433, w1:0.9410013991547669, w2:0.8070815482742622, bias:-0.5867313928092422, loss:0.6092611834998258\n",
      "Epoch:434, w1:0.9411124577482124, w2:0.8070373822019623, bias:-0.5874655903411642, loss:0.6092056693957214\n",
      "Epoch:435, w1:0.9412241804532939, w2:0.8069942711539787, bias:-0.5881981148013926, loss:0.609150396388056\n",
      "Epoch:436, w1:0.9413365648734052, w2:0.806952211020429, bias:-0.588928972061074, loss:0.6090953627581214\n",
      "Epoch:437, w1:0.9414496086196416, w2:0.8069111977042611, bias:-0.5896581679722294, loss:0.6090405667994064\n",
      "Epoch:438, w1:0.9415633093107842, w2:0.8068712271212322, bias:-0.5903857083677956, loss:0.6089860068175162\n",
      "Epoch:439, w1:0.9416776645732853, w2:0.8068322951998879, bias:-0.5911115990616657, loss:0.6089316811300928\n",
      "Epoch:440, w1:0.9417926720412516, w2:0.8067943978815415, bias:-0.5918358458487306, loss:0.6088775880667339\n",
      "Epoch:441, w1:0.9419083293564295, w2:0.8067575311202528, bias:-0.5925584545049204, loss:0.6088237259689154\n",
      "Epoch:442, w1:0.9420246341681892, w2:0.8067216908828067, bias:-0.5932794307872457, loss:0.6087700931899126\n",
      "Epoch:443, w1:0.9421415841335083, w2:0.8066868731486916, bias:-0.593998780433839, loss:0.6087166880947209\n",
      "Epoch:444, w1:0.942259176916957, w2:0.8066530739100782, bias:-0.5947165091639971, loss:0.6086635090599791\n",
      "Epoch:445, w1:0.9423774101906817, w2:0.8066202891717974, bias:-0.595432622678222, loss:0.6086105544738912\n",
      "Epoch:446, w1:0.9424962816343887, w2:0.8065885149513183, bias:-0.5961471266582635, loss:0.6085578227361502\n",
      "Epoch:447, w1:0.9426157889353289, w2:0.8065577472787265, bias:-0.5968600267671612, loss:0.6085053122578613\n",
      "Epoch:448, w1:0.9427359297882815, w2:0.8065279821967014, bias:-0.5975713286492863, loss:0.6084530214614658\n",
      "Epoch:449, w1:0.9428567018955375, w2:0.8064992157604942, bias:-0.5982810379303843, loss:0.6084009487806656\n",
      "Epoch:450, w1:0.9429781029668842, w2:0.8064714440379053, bias:-0.5989891602176173, loss:0.6083490926603475\n",
      "Epoch:451, w1:0.9431001307195886, w2:0.8064446631092613, bias:-0.5996957010996062, loss:0.6082974515565098\n",
      "Epoch:452, w1:0.9432227828783813, w2:0.8064188690673929, bias:-0.6004006661464738, loss:0.608246023936186\n",
      "Epoch:453, w1:0.9433460571754398, w2:0.8063940580176112, bias:-0.601104060909887, loss:0.6081948082773724\n",
      "Epoch:454, w1:0.9434699513503727, w2:0.8063702260776854, bias:-0.6018058909230999, loss:0.6081438030689544\n",
      "Epoch:455, w1:0.9435944631502029, w2:0.8063473693778188, bias:-0.6025061617009967, loss:0.608093006810633\n",
      "Epoch:456, w1:0.9437195903293514, w2:0.8063254840606261, bias:-0.6032048787401345, loss:0.6080424180128523\n",
      "Epoch:457, w1:0.9438453306496205, w2:0.8063045662811098, bias:-0.6039020475187865, loss:0.6079920351967274\n",
      "Epoch:458, w1:0.9439716818801777, w2:0.8062846122066365, bias:-0.604597673496985, loss:0.6079418568939725\n",
      "Epoch:459, w1:0.9440986417975384, w2:0.8062656180169132, bias:-0.6052917621165649, loss:0.6078918816468298\n",
      "Epoch:460, w1:0.9442262081855504, w2:0.8062475799039637, bias:-0.6059843188012067, loss:0.607842108007998\n",
      "Epoch:461, w1:0.9443543788353758, w2:0.8062304940721045, bias:-0.6066753489564802, loss:0.6077925345405624\n",
      "Epoch:462, w1:0.9444831515454756, w2:0.8062143567379207, bias:-0.6073648579698878, loss:0.6077431598179239\n",
      "Epoch:463, w1:0.944612524121592, w2:0.8061991641302423, bias:-0.6080528512109079, loss:0.6076939824237302\n",
      "Epoch:464, w1:0.9447424943767324, w2:0.806184912490119, bias:-0.608739334031039, loss:0.6076450009518063\n",
      "Epoch:465, w1:0.9448730601311518, w2:0.8061715980707969, bias:-0.6094243117638427, loss:0.6075962140060845\n",
      "Epoch:466, w1:0.9450042192123365, w2:0.8061592171376931, bias:-0.6101077897249882, loss:0.6075476202005377\n",
      "Epoch:467, w1:0.9451359694549869, w2:0.8061477659683719, bias:-0.6107897732122956, loss:0.60749921815911\n",
      "Epoch:468, w1:0.945268308701001, w2:0.8061372408525195, bias:-0.6114702675057797, loss:0.6074510065156493\n",
      "Epoch:469, w1:0.9454012347994567, w2:0.8061276380919195, bias:-0.6121492778676946, loss:0.6074029839138401\n",
      "Epoch:470, w1:0.9455347456065956, w2:0.8061189540004279, bias:-0.6128268095425768, loss:0.6073551490071368\n",
      "Epoch:471, w1:0.9456688389858053, w2:0.8061111849039483, bias:-0.6135028677572902, loss:0.6073075004586969\n",
      "Epoch:472, w1:0.945803512807603, w2:0.8061043271404066, bias:-0.6141774577210694, loss:0.6072600369413146\n",
      "Epoch:473, w1:0.9459387649496177, w2:0.8060983770597259, bias:-0.614850584625564, loss:0.6072127571373562\n",
      "Epoch:474, w1:0.9460745932965738, w2:0.8060933310238013, bias:-0.6155222536448832, loss:0.6071656597386936\n",
      "Epoch:475, w1:0.9462109957402735, w2:0.8060891854064747, bias:-0.6161924699356399, loss:0.6071187434466402\n",
      "Epoch:476, w1:0.9463479701795795, w2:0.8060859365935087, bias:-0.6168612386369948, loss:0.6070720069718859\n",
      "Epoch:477, w1:0.9464855145203984, w2:0.8060835809825619, bias:-0.617528564870701, loss:0.6070254490344331\n",
      "Epoch:478, w1:0.9466236266756631, w2:0.806082114983163, bias:-0.6181944537411479, loss:0.6069790683635332\n",
      "Epoch:479, w1:0.9467623045653154, w2:0.8060815350166848, bias:-0.6188589103354063, loss:0.6069328636976226\n",
      "Epoch:480, w1:0.9469015461162892, w2:0.8060818375163188, bias:-0.6195219397232723, loss:0.6068868337842604\n",
      "Epoch:481, w1:0.9470413492624927, w2:0.8060830189270493, bias:-0.6201835469573121, loss:0.6068409773800659\n",
      "Epoch:482, w1:0.9471817119447916, w2:0.8060850757056274, bias:-0.6208437370729065, loss:0.6067952932506553\n",
      "Epoch:483, w1:0.9473226321109913, w2:0.8060880043205451, bias:-0.6215025150882951, loss:0.6067497801705812\n",
      "Epoch:484, w1:0.9474641077158199, w2:0.806091801252009, bias:-0.6221598860046215, loss:0.6067044369232704\n",
      "Epoch:485, w1:0.9476061367209107, w2:0.8060964629919144, bias:-0.6228158548059771, loss:0.6066592623009627\n",
      "Epoch:486, w1:0.9477487170947847, w2:0.8061019860438192, bias:-0.6234704264594467, loss:0.6066142551046507\n",
      "Epoch:487, w1:0.9478918468128336, w2:0.8061083669229173, bias:-0.6241236059151524, loss:0.6065694141440192\n",
      "Epoch:488, w1:0.9480355238573018, w2:0.8061156021560125, bias:-0.6247753981062985, loss:0.6065247382373855\n",
      "Epoch:489, w1:0.9481797462172696, w2:0.8061236882814922, bias:-0.6254258079492162, loss:0.6064802262116391\n",
      "Epoch:490, w1:0.9483245118886352, w2:0.8061326218493002, bias:-0.6260748403434085, loss:0.6064358769021831\n",
      "Epoch:491, w1:0.9484698188740975, w2:0.8061423994209115, bias:-0.6267225001715947, loss:0.6063916891528754\n",
      "Epoch:492, w1:0.9486156651831388, w2:0.8061530175693045, bias:-0.6273687922997552, loss:0.6063476618159697\n",
      "Epoch:493, w1:0.9487620488320068, w2:0.8061644728789349, bias:-0.6280137215771762, loss:0.6063037937520578\n",
      "Epoch:494, w1:0.9489089678436976, w2:0.806176761945709, bias:-0.6286572928364946, loss:0.6062600838300116\n",
      "Epoch:495, w1:0.949056420247938, w2:0.8061898813769569, bias:-0.629299510893743, loss:0.6062165309269261\n",
      "Epoch:496, w1:0.9492044040811681, w2:0.8062038277914056, bias:-0.6299403805483939, loss:0.6061731339280612\n",
      "Epoch:497, w1:0.9493529173865235, w2:0.8062185978191525, bias:-0.6305799065834047, loss:0.6061298917267867\n",
      "Epoch:498, w1:0.9495019582138178, w2:0.8062341881016379, bias:-0.6312180937652629, loss:0.6060868032245248\n",
      "Epoch:499, w1:0.9496515246195255, w2:0.8062505952916187, bias:-0.6318549468440307, loss:0.6060438673306942\n",
      "Epoch:500, w1:0.9498016146667639, w2:0.8062678160531409, bias:-0.6324904705533893, loss:0.6060010829626546\n",
      "Epoch:501, w1:0.949952226425276, w2:0.8062858470615129, bias:-0.6331246696106844, loss:0.6059584490456514\n",
      "Epoch:502, w1:0.9501033579714123, w2:0.806304685003278, bias:-0.6337575487169707, loss:0.6059159645127613\n",
      "Epoch:503, w1:0.9502550073881141, w2:0.8063243265761879, bias:-0.6343891125570565, loss:0.6058736283048367\n",
      "Epoch:504, w1:0.9504071727648951, w2:0.8063447684891751, bias:-0.6350193657995491, loss:0.6058314393704521\n",
      "Epoch:505, w1:0.9505598521978242, w2:0.8063660074623258, bias:-0.6356483130968988, loss:0.60578939666585\n",
      "Epoch:506, w1:0.9507130437895083, w2:0.8063880402268524, bias:-0.6362759590854443, loss:0.6057474991548873\n",
      "Epoch:507, w1:0.9508667456490738, w2:0.8064108635250669, bias:-0.636902308385457, loss:0.6057057458089824\n",
      "Epoch:508, w1:0.9510209558921497, w2:0.8064344741103526, bias:-0.6375273656011863, loss:0.6056641356070616\n",
      "Epoch:509, w1:0.95117567264085, w2:0.8064588687471379, bias:-0.6381511353209037, loss:0.6056226675355072\n",
      "Epoch:510, w1:0.9513308940237558, w2:0.806484044210868, bias:-0.6387736221169482, loss:0.6055813405881052\n",
      "Epoch:511, w1:0.9514866181758977, w2:0.8065099972879777, bias:-0.6393948305457705, loss:0.605540153765993\n",
      "Epoch:512, w1:0.9516428432387387, w2:0.8065367247758642, bias:-0.640014765147978, loss:0.6054991060776082\n",
      "Epoch:513, w1:0.9517995673601559, w2:0.8065642234828597, bias:-0.6406334304483791, loss:0.6054581965386373\n",
      "Epoch:514, w1:0.9519567886944236, w2:0.8065924902282033, bias:-0.6412508309560285, loss:0.6054174241719649\n",
      "Epoch:515, w1:0.9521145054021951, w2:0.8066215218420143, bias:-0.6418669711642714, loss:0.6053767880076224\n",
      "Epoch:516, w1:0.9522727156504858, w2:0.8066513151652639, bias:-0.642481855550788, loss:0.6053362870827391\n",
      "Epoch:517, w1:0.9524314176126548, w2:0.8066818670497481, bias:-0.6430954885776385, loss:0.6052959204414912\n",
      "Epoch:518, w1:0.952590609468388, w2:0.8067131743580599, bias:-0.6437078746913076, loss:0.6052556871350523\n",
      "Epoch:519, w1:0.9527502894036803, w2:0.8067452339635618, bias:-0.6443190183227487, loss:0.6052155862215444\n",
      "Epoch:520, w1:0.952910455610818, w2:0.806778042750358, bias:-0.6449289238874288, loss:0.6051756167659886\n",
      "Epoch:521, w1:0.9530711062883611, w2:0.806811597613267, bias:-0.6455375957853728, loss:0.6051357778402577\n",
      "Epoch:522, w1:0.953232239641126, w2:0.8068458954577938, bias:-0.6461450384012082, loss:0.6050960685230253\n",
      "Epoch:523, w1:0.953393853880168, w2:0.8068809332001021, bias:-0.6467512561042091, loss:0.6050564878997204\n",
      "Epoch:524, w1:0.9535559472227633, w2:0.8069167077669867, bias:-0.6473562532483412, loss:0.6050170350624784\n",
      "Epoch:525, w1:0.953718517892392, w2:0.8069532160958456, bias:-0.6479600341723057, loss:0.6049777091100936\n",
      "Epoch:526, w1:0.9538815641187204, w2:0.8069904551346527, bias:-0.6485626031995838, loss:0.6049385091479721\n",
      "Epoch:527, w1:0.9540450841375832, w2:0.8070284218419298, bias:-0.649163964638481, loss:0.6048994342880863\n",
      "Epoch:528, w1:0.9542090761909662, w2:0.8070671131867185, bias:-0.6497641227821715, loss:0.6048604836489265\n",
      "Epoch:529, w1:0.954373538526989, w2:0.8071065261485533, bias:-0.6503630819087424, loss:0.6048216563554558\n",
      "Epoch:530, w1:0.9545384693998875, w2:0.8071466577174328, bias:-0.6509608462812375, loss:0.6047829515390643\n",
      "Epoch:531, w1:0.9547038670699958, w2:0.8071875048937925, bias:-0.651557420147702, loss:0.6047443683375227\n",
      "Epoch:532, w1:0.9548697298037294, w2:0.8072290646884773, bias:-0.6521528077412265, loss:0.6047059058949379\n",
      "Epoch:533, w1:0.9550360558735675, w2:0.8072713341227129, bias:-0.6527470132799909, loss:0.6046675633617079\n",
      "Epoch:534, w1:0.9552028435580356, w2:0.8073143102280786, bias:-0.6533400409673084, loss:0.6046293398944763\n",
      "Epoch:535, w1:0.9553700911416881, w2:0.8073579900464795, bias:-0.6539318949916697, loss:0.6045912346560889\n",
      "Epoch:536, w1:0.9555377969150907, w2:0.8074023706301181, bias:-0.654522579526787, loss:0.6045532468155487\n",
      "Epoch:537, w1:0.9557059591748029, w2:0.8074474490414673, bias:-0.6551120987316378, loss:0.6045153755479729\n",
      "Epoch:538, w1:0.9558745762233615, w2:0.807493222353242, bias:-0.6557004567505084, loss:0.604477620034549\n",
      "Epoch:539, w1:0.9560436463692618, w2:0.8075396876483715, bias:-0.6562876577130383, loss:0.6044399794624912\n",
      "Epoch:540, w1:0.9562131679269412, w2:0.8075868420199718, bias:-0.6568737057342638, loss:0.604402453024998\n",
      "Epoch:541, w1:0.9563831392167619, w2:0.8076346825713175, bias:-0.6574586049146615, loss:0.6043650399212096\n",
      "Epoch:542, w1:0.9565535585649929, w2:0.8076832064158145, bias:-0.658042359340192, loss:0.6043277393561648\n",
      "Epoch:543, w1:0.9567244243037933, w2:0.8077324106769715, bias:-0.6586249730823438, loss:0.6042905505407593\n",
      "Epoch:544, w1:0.9568957347711947, w2:0.8077822924883729, bias:-0.6592064501981767, loss:0.6042534726917044\n",
      "Epoch:545, w1:0.957067488311084, w2:0.8078328489936503, bias:-0.6597867947303652, loss:0.6042165050314839\n",
      "Epoch:546, w1:0.957239683273186, w2:0.8078840773464555, bias:-0.660366010707242, loss:0.6041796467883149\n",
      "Epoch:547, w1:0.9574123180130462, w2:0.8079359747104321, bias:-0.6609441021428417, loss:0.6041428971961053\n",
      "Epoch:548, w1:0.9575853908920138, w2:0.8079885382591881, bias:-0.6615210730369437, loss:0.6041062554944134\n",
      "Epoch:549, w1:0.9577589002772241, w2:0.8080417651762679, bias:-0.6620969273751158, loss:0.6040697209284076\n",
      "Epoch:550, w1:0.9579328445415817, w2:0.8080956526551247, bias:-0.6626716691287574, loss:0.6040332927488262\n",
      "Epoch:551, w1:0.9581072220637429, w2:0.8081501978990927, bias:-0.6632453022551427, loss:0.6039969702119378\n",
      "Epoch:552, w1:0.9582820312280989, w2:0.8082053981213593, bias:-0.6638178306974635, loss:0.6039607525795001\n",
      "Epoch:553, w1:0.9584572704247584, w2:0.8082612505449376, bias:-0.6643892583848727, loss:0.6039246391187232\n",
      "Epoch:554, w1:0.9586329380495305, w2:0.8083177524026385, bias:-0.6649595892325274, loss:0.6038886291022278\n",
      "Epoch:555, w1:0.958809032503908, w2:0.8083749009370431, bias:-0.6655288271416312, loss:0.6038527218080081\n",
      "Epoch:556, w1:0.9589855521950497, w2:0.8084326934004751, bias:-0.6660969759994777, loss:0.6038169165193925\n",
      "Epoch:557, w1:0.9591624955357635, w2:0.8084911270549728, bias:-0.6666640396794931, loss:0.6037812125250048\n",
      "Epoch:558, w1:0.9593398609444899, w2:0.808550199172262, bias:-0.6672300220412788, loss:0.6037456091187277\n",
      "Epoch:559, w1:0.9595176468452843, w2:0.8086099070337278, bias:-0.6677949269306545, loss:0.603710105599663\n",
      "Epoch:560, w1:0.9596958516678004, w2:0.8086702479303874, bias:-0.6683587581797005, loss:0.6036747012720953\n",
      "Epoch:561, w1:0.9598744738472729, w2:0.8087312191628625, bias:-0.6689215196068004, loss:0.6036393954454545\n",
      "Epoch:562, w1:0.9600535118245008, w2:0.8087928180413513, bias:-0.6694832150166835, loss:0.6036041874342783\n",
      "Epoch:563, w1:0.9602329640458307, w2:0.8088550418856014, bias:-0.6700438482004675, loss:0.6035690765581756\n",
      "Epoch:564, w1:0.9604128289631392, w2:0.8089178880248822, bias:-0.6706034229357005, loss:0.6035340621417903\n",
      "Epoch:565, w1:0.9605931050338166, w2:0.8089813537979571, bias:-0.6711619429864039, loss:0.6034991435147645\n",
      "Epoch:566, w1:0.9607737907207498, w2:0.8090454365530564, bias:-0.6717194121031137, loss:0.6034643200117021\n",
      "Epoch:567, w1:0.9609548844923055, w2:0.8091101336478496, bias:-0.6722758340229238, loss:0.6034295909721343\n",
      "Epoch:568, w1:0.9611363848223136, w2:0.8091754424494179, bias:-0.672831212469527, loss:0.6033949557404829\n",
      "Epoch:569, w1:0.9613182901900499, w2:0.809241360334227, bias:-0.673385551153258, loss:0.6033604136660243\n",
      "Epoch:570, w1:0.9615005990802198, w2:0.8093078846880996, bias:-0.6739388537711348, loss:0.6033259641028568\n",
      "Epoch:571, w1:0.9616833099829414, w2:0.8093750129061877, bias:-0.6744911240069006, loss:0.603291606409863\n",
      "Epoch:572, w1:0.9618664213937288, w2:0.8094427423929461, bias:-0.6750423655310658, loss:0.603257339950677\n",
      "Epoch:573, w1:0.9620499318134754, w2:0.809511070562104, bias:-0.6755925820009498, loss:0.6032231640936495\n",
      "Epoch:574, w1:0.9622338397484372, w2:0.8095799948366387, bias:-0.6761417770607226, loss:0.6031890782118129\n",
      "Epoch:575, w1:0.9624181437102163, w2:0.8096495126487474, bias:-0.6766899543414463, loss:0.6031550816828487\n",
      "Epoch:576, w1:0.9626028422157439, w2:0.8097196214398208, bias:-0.6772371174611166, loss:0.6031211738890531\n",
      "Epoch:577, w1:0.9627879337872642, w2:0.8097903186604155, bias:-0.6777832700247046, loss:0.6030873542173028\n",
      "Epoch:578, w1:0.9629734169523179, w2:0.8098616017702267, bias:-0.6783284156241979, loss:0.6030536220590235\n",
      "Epoch:579, w1:0.9631592902437248, w2:0.8099334682380612, bias:-0.6788725578386419, loss:0.6030199768101551\n",
      "Epoch:580, w1:0.9633455521995685, w2:0.8100059155418105, bias:-0.6794157002341812, loss:0.6029864178711203\n",
      "Epoch:581, w1:0.963532201363179, w2:0.810078941168423, bias:-0.6799578463641006, loss:0.6029529446467916\n",
      "Epoch:582, w1:0.9637192362831164, w2:0.8101525426138781, bias:-0.6804989997688664, loss:0.6029195565464578\n",
      "Epoch:583, w1:0.9639066555131551, w2:0.810226717383158, bias:-0.681039163976167, loss:0.6028862529837945\n",
      "Epoch:584, w1:0.9640944576122668, w2:0.8103014629902211, bias:-0.6815783425009544, loss:0.602853033376829\n",
      "Epoch:585, w1:0.964282641144604, w2:0.8103767769579755, bias:-0.6821165388454844, loss:0.6028198971479118\n",
      "Epoch:586, w1:0.9644712046794844, w2:0.8104526568182515, bias:-0.682653756499358, loss:0.6027868437236826\n",
      "Epoch:587, w1:0.9646601467913739, w2:0.8105291001117749, bias:-0.6831899989395617, loss:0.6027538725350404\n",
      "Epoch:588, w1:0.9648494660598704, w2:0.8106061043881402, bias:-0.6837252696305081, loss:0.6027209830171122\n",
      "Epoch:589, w1:0.9650391610696881, w2:0.8106836672057836, bias:-0.6842595720240766, loss:0.602688174609222\n",
      "Epoch:590, w1:0.9652292304106406, w2:0.8107617861319564, bias:-0.6847929095596541, loss:0.6026554467548607\n",
      "Epoch:591, w1:0.965419672677625, w2:0.8108404587426982, bias:-0.6853252856641747, loss:0.6026227989016554\n",
      "Epoch:592, w1:0.9656104864706059, w2:0.8109196826228099, bias:-0.6858567037521607, loss:0.6025902305013383\n",
      "Epoch:593, w1:0.965801670394599, w2:0.8109994553658276, bias:-0.6863871672257622, loss:0.6025577410097189\n",
      "Epoch:594, w1:0.965993223059655, w2:0.8110797745739955, bias:-0.6869166794747978, loss:0.6025253298866523\n",
      "Epoch:595, w1:0.9661851430808438, w2:0.8111606378582391, bias:-0.6874452438767943, loss:0.6024929965960107\n",
      "Epoch:596, w1:0.9663774290782382, w2:0.8112420428381393, bias:-0.6879728637970266, loss:0.6024607406056532\n",
      "Epoch:597, w1:0.9665700796768979, w2:0.8113239871419052, bias:-0.688499542588558, loss:0.6024285613873976\n",
      "Epoch:598, w1:0.9667630935068537, w2:0.8114064684063482, bias:-0.6890252835922794, loss:0.6023964584169913\n",
      "Epoch:599, w1:0.9669564692030914, w2:0.811489484276855, bias:-0.6895500901369499, loss:0.6023644311740811\n",
      "Epoch:600, w1:0.9671502054055358, w2:0.8115730324073614, bias:-0.6900739655392354, loss:0.6023324791421875\n",
      "Epoch:601, w1:0.967344300759035, w2:0.8116571104603262, bias:-0.6905969131037488, loss:0.6023006018086734\n",
      "Epoch:602, w1:0.9675387539133444, w2:0.8117417161067042, bias:-0.6911189361230896, loss:0.6022687986647178\n",
      "Epoch:603, w1:0.9677335635231112, w2:0.8118268470259208, bias:-0.6916400378778826, loss:0.6022370692052875\n",
      "Epoch:604, w1:0.967928728247858, w2:0.8119125009058449, bias:-0.692160221636818, loss:0.6022054129291091\n",
      "Epoch:605, w1:0.9681242467519676, w2:0.811998675442763, bias:-0.69267949065669, loss:0.6021738293386409\n",
      "Epoch:606, w1:0.9683201177046669, w2:0.8120853683413536, bias:-0.6931978481824361, loss:0.6021423179400472\n",
      "Epoch:607, w1:0.9685163397800114, w2:0.8121725773146599, bias:-0.6937152974471765, loss:0.6021108782431698\n",
      "Epoch:608, w1:0.9687129116568695, w2:0.8122603000840647, bias:-0.6942318416722525, loss:0.6020795097615008\n",
      "Epoch:609, w1:0.9689098320189068, w2:0.812348534379264, bias:-0.6947474840672657, loss:0.6020482120121566\n",
      "Epoch:610, w1:0.9691070995545708, w2:0.812437277938241, bias:-0.6952622278301169, loss:0.6020169845158514\n",
      "Epoch:611, w1:0.9693047129570745, w2:0.8125265285072402, bias:-0.6957760761470445, loss:0.6019858267968701\n",
      "Epoch:612, w1:0.9695026709243821, w2:0.8126162838407412, bias:-0.6962890321926631, loss:0.601954738383042\n",
      "Epoch:613, w1:0.9697009721591925, w2:0.8127065417014335, bias:-0.6968010991300025, loss:0.6019237188057164\n",
      "Epoch:614, w1:0.969899615368924, w2:0.81279729986019, bias:-0.6973122801105456, loss:0.6018927675997335\n",
      "Epoch:615, w1:0.9700985992656993, w2:0.8128885560960416, bias:-0.6978225782742669, loss:0.6018618843034029\n",
      "Epoch:616, w1:0.9702979225663297, w2:0.8129803081961513, bias:-0.6983319967496708, loss:0.601831068458474\n",
      "Epoch:617, w1:0.9704975839923, w2:0.8130725539557885, bias:-0.6988405386538302, loss:0.6018003196101137\n",
      "Epoch:618, w1:0.9706975822697528, w2:0.8131652911783036, bias:-0.6993482070924237, loss:0.6017696373068797\n",
      "Epoch:619, w1:0.9708979161294734, w2:0.8132585176751022, bias:-0.6998550051597745, loss:0.6017390211006963\n",
      "Epoch:620, w1:0.9710985843068747, w2:0.8133522312656193, bias:-0.7003609359388875, loss:0.6017084705468284\n",
      "Epoch:621, w1:0.9712995855419816, w2:0.8134464297772945, bias:-0.7008660025014877, loss:0.6016779852038586\n",
      "Epoch:622, w1:0.9715009185794162, w2:0.8135411110455459, bias:-0.7013702079080577, loss:0.6016475646336619\n",
      "Epoch:623, w1:0.9717025821683822, w2:0.8136362729137451, bias:-0.7018735552078756, loss:0.6016172084013807\n",
      "Epoch:624, w1:0.9719045750626503, w2:0.8137319132331914, bias:-0.7023760474390521, loss:0.6015869160754023\n",
      "Epoch:625, w1:0.9721068960205422, w2:0.813828029863087, bias:-0.7028776876285684, loss:0.6015566872273332\n",
      "Epoch:626, w1:0.9723095438049169, w2:0.8139246206705114, bias:-0.7033784787923131, loss:0.6015265214319775\n",
      "Epoch:627, w1:0.9725125171831541, w2:0.8140216835303963, bias:-0.70387842393512, loss:0.6014964182673107\n",
      "Epoch:628, w1:0.9727158149271407, w2:0.8141192163255003, bias:-0.7043775260508051, loss:0.6014663773144585\n",
      "Epoch:629, w1:0.9729194358132544, w2:0.8142172169463842, bias:-0.7048757881222034, loss:0.6014363981576722\n",
      "Epoch:630, w1:0.97312337862235, w2:0.8143156832913852, bias:-0.7053732131212066, loss:0.6014064803843066\n",
      "Epoch:631, w1:0.9733276421397439, w2:0.8144146132665926, bias:-0.7058698040087992, loss:0.6013766235847962\n",
      "Epoch:632, w1:0.9735322251551992, w2:0.8145140047858226, bias:-0.7063655637350958, loss:0.6013468273526327\n",
      "Epoch:633, w1:0.9737371264629111, w2:0.8146138557705932, bias:-0.7068604952393781, loss:0.6013170912843425\n",
      "Epoch:634, w1:0.9739423448614919, w2:0.8147141641500996, bias:-0.7073546014501307, loss:0.6012874149794653\n",
      "Epoch:635, w1:0.9741478791539565, w2:0.8148149278611889, bias:-0.7078478852850787, loss:0.6012577980405289\n",
      "Epoch:636, w1:0.9743537281477075, w2:0.8149161448483362, bias:-0.7083403496512234, loss:0.6012282400730302\n",
      "Epoch:637, w1:0.9745598906545204, w2:0.8150178130636189, bias:-0.7088319974448788, loss:0.601198740685412\n",
      "Epoch:638, w1:0.9747663654905294, w2:0.8151199304666926, bias:-0.7093228315517083, loss:0.6011692994890406\n",
      "Epoch:639, w1:0.9749731514762122, w2:0.8152224950247666, bias:-0.7098128548467604, loss:0.6011399160981848\n",
      "Epoch:640, w1:0.9751802474363758, w2:0.8153255047125789, bias:-0.7103020701945052, loss:0.601110590129995\n",
      "Epoch:641, w1:0.9753876522001418, w2:0.815428957512372, bias:-0.71079048044887, loss:0.6010813212044803\n",
      "Epoch:642, w1:0.9755953646009321, w2:0.8155328514138683, bias:-0.7112780884532757, loss:0.6010521089444885\n",
      "Epoch:643, w1:0.9758033834764542, w2:0.8156371844142458, bias:-0.711764897040672, loss:0.6010229529756848\n",
      "Epoch:644, w1:0.9760117076686867, w2:0.8157419545181136, bias:-0.7122509090335738, loss:0.6009938529265308\n",
      "Epoch:645, w1:0.9762203360238653, w2:0.8158471597374878, bias:-0.7127361272440965, loss:0.6009648084282638\n",
      "Epoch:646, w1:0.9764292673924677, w2:0.8159527980917669, bias:-0.7132205544739916, loss:0.6009358191148761\n",
      "Epoch:647, w1:0.9766385006292003, w2:0.8160588676077082, bias:-0.713704193514682, loss:0.6009068846230946\n",
      "Epoch:648, w1:0.976848034592983, w2:0.816165366319403, bias:-0.7141870471472976, loss:0.600878004592361\n",
      "Epoch:649, w1:0.9770578681469352, w2:0.8162722922682527, bias:-0.7146691181427106, loss:0.6008491786648106\n",
      "Epoch:650, w1:0.9772680001583619, w2:0.8163796435029452, bias:-0.7151504092615705, loss:0.6008204064852531\n",
      "Epoch:651, w1:0.9774784294987391, w2:0.8164874180794304, bias:-0.7156309232543392, loss:0.6007916877011529\n",
      "Epoch:652, w1:0.9776891550436998, w2:0.8165956140608963, bias:-0.7161106628613262, loss:0.6007630219626081\n",
      "Epoch:653, w1:0.9779001756730199, w2:0.8167042295177456, bias:-0.7165896308127232, loss:0.6007344089223329\n",
      "Epoch:654, w1:0.9781114902706042, w2:0.8168132625275711, bias:-0.7170678298286391, loss:0.600705848235636\n",
      "Epoch:655, w1:0.978323097724472, w2:0.8169227111751328, bias:-0.717545262619135, loss:0.6006773395604033\n",
      "Epoch:656, w1:0.9785349969267436, w2:0.8170325735523335, bias:-0.718021931884258, loss:0.6006488825570773\n",
      "Epoch:657, w1:0.978747186773626, w2:0.8171428477581953, bias:-0.7184978403140766, loss:0.6006204768886386\n",
      "Epoch:658, w1:0.9789596661653991, w2:0.8172535318988363, bias:-0.7189729905887148, loss:0.6005921222205871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9789596661653991, 0.8172535318988363, -0.7189729905887148)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(X_train_scaled['age'], X_train_scaled['affordibility'], y_train, 1000, 0.6006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.1257615],\n",
       "        [0.7468925]], dtype=float32),\n",
       " array([-0.680116], dtype=float32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef, intercept"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
